{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение \"токсичных\" комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заказчик проекта — интернет-магазин \"Викишоп\". Магазин планирует запуск нового сервиса, где пользователи смогут редактировать и добавлять описание товаров, как в вики-сообществах. \n",
    "\n",
    "Цель проекта — создать модель, которая сможет выявить \"токсичные\" комментарии, которые следует отправить на модерацию.\n",
    "\n",
    "В ходе работы мы загрузим и предобработаем данные. Затем обучим несколько разных моделей, и по результатам их работы выявим наилучшую по целевой метрике качества — F1. Её значение должно быть не менее 0.75 по условиям заказчика. Работа лучшей модели будет проверена на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете присутствует столбец `Unnamed: 0`, в котором дублируется индексация, — прежде чем продолжить, избавимся от него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После преобразования в датасете осталось два столбца:\n",
    "- `text` — содержит англоязычный текст комментария;\n",
    "- `toxic` — оценка, является ли комментарий \"токсичным\", нуждающимся в модерации — **целевой** признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Баланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде, чем перейти к обучению моделей, проверим баланс классов в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()                                           # общее количество объектов каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = data['toxic'].value_counts(normalize=True)           # посмотрим на графике        \n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, имеется дисбаланс классов — на один токсичный комментарий приходится 8.84 обычных — все-таки большинство пользователей \"адекватные\" и пишут нормальные комментарии. Дисбаланс нужно будет учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на несколько токсичных комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152498</th>\n",
       "      <td>SimCopter Shenanigans\\nHiya. I originally foll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152741</th>\n",
       "      <td>Idiocracy \\n\\nIf you need a 13 section FAQ to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29219</th>\n",
       "      <td>Perhaps there's a wikipedia for adults somewhe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102057</th>\n",
       "      <td>\"\\n\\n Idiot!  \\n\\nQuick!  Lock your talk page!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140134</th>\n",
       "      <td>Oh, did little mrs. pussy get his feelings hur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105392</th>\n",
       "      <td>A bunch of non-academic clowns are now censori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137637</th>\n",
       "      <td>a complete tosser. I need to get a girlfriend ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38529</th>\n",
       "      <td>Who the fuck are you!? Stay the fuck away from...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85470</th>\n",
       "      <td>You absolute spastic\\n\\nI am right, Username72...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53615</th>\n",
       "      <td>Are you kidding me? \\n\\nAre you fucking stupid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "152498  SimCopter Shenanigans\\nHiya. I originally foll...      1\n",
       "152741  Idiocracy \\n\\nIf you need a 13 section FAQ to ...      1\n",
       "29219   Perhaps there's a wikipedia for adults somewhe...      1\n",
       "102057  \"\\n\\n Idiot!  \\n\\nQuick!  Lock your talk page!...      1\n",
       "140134  Oh, did little mrs. pussy get his feelings hur...      1\n",
       "105392  A bunch of non-academic clowns are now censori...      1\n",
       "137637  a complete tosser. I need to get a girlfriend ...      1\n",
       "38529   Who the fuck are you!? Stay the fuck away from...      1\n",
       "85470   You absolute spastic\\n\\nI am right, Username72...      1\n",
       "53615   Are you kidding me? \\n\\nAre you fucking stupid...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['toxic']==1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в комментарии есть `fuck` или `ass` его нужно увидеть модераторам. Именно такие слова и будут сигналом для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели тексты в датасете сначала следует привести к начальной форме — лемме. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() # создаем объект "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"bats\")     # проверка работы на английском слове"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы  лемматизатора нам понадобятся POS-теги (part-of-speech) — указатели, которые позволят правильно определить лемму слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, которая вернет POS-тег для слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text, r_mask = r'[^a-zA-Z]'):\n",
    "    \"\"\"\n",
    "    Данная функция принимает на вход текст и лемматизирует его.\n",
    "    \n",
    "    Перед лемматизацией текст будет приведет к нижнему регистру.\n",
    "   \n",
    "    Ожидается англоязычный текст — если использован другой язык, необходимо переопределить параметр функции r_mask\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    lemm_text = \" \".join(lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text))\n",
    "    \n",
    "    cleared_text = re.sub(r_mask, ' ', lemm_text)\n",
    "    \n",
    "    return \" \".join(cleared_text.split( ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 23s, sys: 1min 54s, total: 21min 18s\n",
      "Wall time: 21min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['lemm_text'] = data['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head(5)         # тексты до лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits make under my userna...\n",
       "1    d aww he match this background colour i m seem...\n",
       "2    hey man i m really not try to edit war it s ju...\n",
       "3    more i ca n t make any real suggestion on impr...\n",
       "4    you sir be my hero any chance you remember wha...\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemm_text'].head(5)    # тексты после лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшей работе нам понадобится только лемматизированные тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весь датасет разобьем на 3 выборки — обучающую, валидационную и тестовую — в соотношении 3:1:1. На обучающей подберем оптимальные гиперпараметры моделей путем кросс-валидации. На валидационной проверим какая модель показывает лучший результат. Адекватность работы лучшей модели проверим на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "features = data.drop(['toxic'], axis = 1)\n",
    "\n",
    "#первое применение train_test_split разобьет выборку в соотношении 60:40 — 60% для обучающей и 40% для валидационной и тестовой\n",
    "\n",
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(features, \n",
    "                                                                                        target, \n",
    "                                                                                        test_size = 0.4, \n",
    "                                                                                        random_state = 270822)\n",
    "\n",
    "#повторное применение train_test_split разобьет 40% попалам на валидационную и тестовые выборки по 20%\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_test, \n",
    "                                                                            target_valid_test, \n",
    "                                                                            test_size = 0.5,\n",
    "                                                                            random_state = 270822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# загружаем и сохраняем в переменную stopwords слова без смысловой нагрузки\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект класса TfidVectorizer и передаем ему список стоп-слов\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем TF-IDF для обучающей выборки \n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values)\n",
    "\n",
    "\n",
    "features_valid = count_tf_idf.transform(features_valid['lemm_text'].values)\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размерность обучающей, валидационной и тестовой выборок — количество признаков должно совпадать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95575, 115598)\n",
      "(31858, 115598)\n",
      "(31859, 115598)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модеди LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки готовы и настоло время обучить первую модель. В качестве метрики качества будем использовать F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект модели, указываем параметр class-weight т.к. признаки не сбалансированы\n",
    "model = LogisticRegression(random_state = 270822,\n",
    "                          class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем словарь гиперпараметров по которым \"пробежимся\" с помощью GridSearch\n",
    "\n",
    "h_params = [{'solver':['lbfgs', 'saga'],     # алгоритм для оптимизации и решения проблемы классификации\n",
    "             'C': [1, 10]}]                  # регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          random_state=270822),\n",
       "             param_grid=[{'C': [1, 10], 'solver': ['lbfgs', 'saga']}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "grid = GridSearchCV(model, h_params, scoring = 'f1')\n",
    "grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с данными параметрами и проверим работу на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression(random_state = 270822,\n",
    "                              class_weight = 'balanced',\n",
    "                              C = 10,\n",
    "                              solver = 'lbfgs')\n",
    "\n",
    "model_LR.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid_LR = model_LR.predict(features_valid)\n",
    "f1_valid_LR = f1_score(target_valid, predictions_valid_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608360218824519"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_valid_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия позволила дала необхожимую метрику F1 на валидационной выборке. Посмотрим, как справятся с задачей другие модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 12s, sys: 1.8 s, total: 21min 14s\n",
      "Wall time: 21min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              random_state=270822),\n",
       "             param_grid=[{'max_depth': [30, 32, 34, 36, 38, 40, 42, 44, 46, 48,\n",
       "                                        50]}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 270822,\n",
    "                               class_weight = 'balanced')\n",
    "\n",
    "\n",
    "h_params = [{'max_depth':[x for x in range(30,51,2)]}]\n",
    "\n",
    "grid = GridSearchCV(model, h_params, scoring='f1')\n",
    "grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 44}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель с лучшими параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DTC = DecisionTreeClassifier(random_state = 270822,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   max_depth = 44)\n",
    "\n",
    "model_DTC.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid_DTC = model_DTC.predict(features_valid)\n",
    "f1_valid_DTC = f1_score(target_valid, predictions_valid_DTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423311922293592"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_valid_DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающее древо не справилось с задачей - метрика не дотягивает до нужной на валидационной выборке. Посмотрим на работу более сложной модели с градиентным бустингом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной работы модели CatBoostClassifier передадим ей словарь с весами классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(target_train)\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = classes, y = target_train)\n",
    "class_weights = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(random_state = 270822,\n",
    "                          class_weights = class_weights,\n",
    "                          iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.315861\n",
      "0:\tlearn: 0.5817706\ttotal: 2.49s\tremaining: 8m 15s\n",
      "1:\tlearn: 0.5395339\ttotal: 4.36s\tremaining: 7m 11s\n",
      "2:\tlearn: 0.5207329\ttotal: 6.13s\tremaining: 6m 42s\n",
      "3:\tlearn: 0.5008723\ttotal: 7.93s\tremaining: 6m 28s\n",
      "4:\tlearn: 0.4806693\ttotal: 9.69s\tremaining: 6m 18s\n",
      "5:\tlearn: 0.4686638\ttotal: 11.4s\tremaining: 6m 10s\n",
      "6:\tlearn: 0.4565073\ttotal: 13.3s\tremaining: 6m 6s\n",
      "7:\tlearn: 0.4486172\ttotal: 15.1s\tremaining: 6m 1s\n",
      "8:\tlearn: 0.4385544\ttotal: 16.8s\tremaining: 5m 56s\n",
      "9:\tlearn: 0.4305950\ttotal: 18.5s\tremaining: 5m 52s\n",
      "10:\tlearn: 0.4239935\ttotal: 20.3s\tremaining: 5m 48s\n",
      "11:\tlearn: 0.4177078\ttotal: 22s\tremaining: 5m 44s\n",
      "12:\tlearn: 0.4134897\ttotal: 23.8s\tremaining: 5m 42s\n",
      "13:\tlearn: 0.4078997\ttotal: 25.5s\tremaining: 5m 39s\n",
      "14:\tlearn: 0.4026653\ttotal: 27.2s\tremaining: 5m 36s\n",
      "15:\tlearn: 0.3975219\ttotal: 29s\tremaining: 5m 33s\n",
      "16:\tlearn: 0.3935553\ttotal: 30.8s\tremaining: 5m 31s\n",
      "17:\tlearn: 0.3894207\ttotal: 32.4s\tremaining: 5m 28s\n",
      "18:\tlearn: 0.3860693\ttotal: 34.3s\tremaining: 5m 26s\n",
      "19:\tlearn: 0.3832916\ttotal: 35.9s\tremaining: 5m 23s\n",
      "20:\tlearn: 0.3799461\ttotal: 37.8s\tremaining: 5m 22s\n",
      "21:\tlearn: 0.3767405\ttotal: 39.5s\tremaining: 5m 19s\n",
      "22:\tlearn: 0.3735460\ttotal: 41.2s\tremaining: 5m 17s\n",
      "23:\tlearn: 0.3699373\ttotal: 43.1s\tremaining: 5m 15s\n",
      "24:\tlearn: 0.3674599\ttotal: 44.8s\tremaining: 5m 13s\n",
      "25:\tlearn: 0.3658704\ttotal: 46.4s\tremaining: 5m 10s\n",
      "26:\tlearn: 0.3638099\ttotal: 48.2s\tremaining: 5m 8s\n",
      "27:\tlearn: 0.3609515\ttotal: 49.9s\tremaining: 5m 6s\n",
      "28:\tlearn: 0.3586299\ttotal: 51.7s\tremaining: 5m 4s\n",
      "29:\tlearn: 0.3560554\ttotal: 53.5s\tremaining: 5m 2s\n",
      "30:\tlearn: 0.3543143\ttotal: 55.2s\tremaining: 5m 1s\n",
      "31:\tlearn: 0.3522518\ttotal: 57s\tremaining: 4m 59s\n",
      "32:\tlearn: 0.3505678\ttotal: 58.8s\tremaining: 4m 57s\n",
      "33:\tlearn: 0.3483390\ttotal: 1m\tremaining: 4m 55s\n",
      "34:\tlearn: 0.3462622\ttotal: 1m 2s\tremaining: 4m 53s\n",
      "35:\tlearn: 0.3441197\ttotal: 1m 4s\tremaining: 4m 51s\n",
      "36:\tlearn: 0.3416321\ttotal: 1m 5s\tremaining: 4m 49s\n",
      "37:\tlearn: 0.3399455\ttotal: 1m 7s\tremaining: 4m 47s\n",
      "38:\tlearn: 0.3382616\ttotal: 1m 9s\tremaining: 4m 45s\n",
      "39:\tlearn: 0.3360346\ttotal: 1m 10s\tremaining: 4m 43s\n",
      "40:\tlearn: 0.3336326\ttotal: 1m 12s\tremaining: 4m 41s\n",
      "41:\tlearn: 0.3318472\ttotal: 1m 14s\tremaining: 4m 39s\n",
      "42:\tlearn: 0.3292289\ttotal: 1m 15s\tremaining: 4m 37s\n",
      "43:\tlearn: 0.3275508\ttotal: 1m 17s\tremaining: 4m 35s\n",
      "44:\tlearn: 0.3253845\ttotal: 1m 19s\tremaining: 4m 33s\n",
      "45:\tlearn: 0.3237677\ttotal: 1m 21s\tremaining: 4m 31s\n",
      "46:\tlearn: 0.3221258\ttotal: 1m 22s\tremaining: 4m 29s\n",
      "47:\tlearn: 0.3195053\ttotal: 1m 24s\tremaining: 4m 27s\n",
      "48:\tlearn: 0.3179857\ttotal: 1m 26s\tremaining: 4m 25s\n",
      "49:\tlearn: 0.3163016\ttotal: 1m 27s\tremaining: 4m 23s\n",
      "50:\tlearn: 0.3145535\ttotal: 1m 29s\tremaining: 4m 21s\n",
      "51:\tlearn: 0.3123638\ttotal: 1m 31s\tremaining: 4m 19s\n",
      "52:\tlearn: 0.3100574\ttotal: 1m 32s\tremaining: 4m 17s\n",
      "53:\tlearn: 0.3084959\ttotal: 1m 34s\tremaining: 4m 15s\n",
      "54:\tlearn: 0.3073017\ttotal: 1m 36s\tremaining: 4m 13s\n",
      "55:\tlearn: 0.3059814\ttotal: 1m 37s\tremaining: 4m 11s\n",
      "56:\tlearn: 0.3047975\ttotal: 1m 39s\tremaining: 4m 10s\n",
      "57:\tlearn: 0.3033347\ttotal: 1m 41s\tremaining: 4m 8s\n",
      "58:\tlearn: 0.3013057\ttotal: 1m 43s\tremaining: 4m 6s\n",
      "59:\tlearn: 0.3000181\ttotal: 1m 44s\tremaining: 4m 4s\n",
      "60:\tlearn: 0.2984931\ttotal: 1m 46s\tremaining: 4m 2s\n",
      "61:\tlearn: 0.2971671\ttotal: 1m 48s\tremaining: 4m\n",
      "62:\tlearn: 0.2959446\ttotal: 1m 49s\tremaining: 3m 59s\n",
      "63:\tlearn: 0.2947255\ttotal: 1m 51s\tremaining: 3m 57s\n",
      "64:\tlearn: 0.2934991\ttotal: 1m 53s\tremaining: 3m 55s\n",
      "65:\tlearn: 0.2926101\ttotal: 1m 55s\tremaining: 3m 53s\n",
      "66:\tlearn: 0.2906904\ttotal: 1m 56s\tremaining: 3m 51s\n",
      "67:\tlearn: 0.2894721\ttotal: 1m 58s\tremaining: 3m 50s\n",
      "68:\tlearn: 0.2883326\ttotal: 2m\tremaining: 3m 48s\n",
      "69:\tlearn: 0.2871416\ttotal: 2m 1s\tremaining: 3m 46s\n",
      "70:\tlearn: 0.2859046\ttotal: 2m 3s\tremaining: 3m 44s\n",
      "71:\tlearn: 0.2848566\ttotal: 2m 5s\tremaining: 3m 42s\n",
      "72:\tlearn: 0.2837215\ttotal: 2m 6s\tremaining: 3m 40s\n",
      "73:\tlearn: 0.2824970\ttotal: 2m 8s\tremaining: 3m 38s\n",
      "74:\tlearn: 0.2817125\ttotal: 2m 10s\tremaining: 3m 36s\n",
      "75:\tlearn: 0.2803139\ttotal: 2m 11s\tremaining: 3m 34s\n",
      "76:\tlearn: 0.2793410\ttotal: 2m 13s\tremaining: 3m 33s\n",
      "77:\tlearn: 0.2781198\ttotal: 2m 15s\tremaining: 3m 31s\n",
      "78:\tlearn: 0.2773788\ttotal: 2m 16s\tremaining: 3m 29s\n",
      "79:\tlearn: 0.2766390\ttotal: 2m 18s\tremaining: 3m 27s\n",
      "80:\tlearn: 0.2754896\ttotal: 2m 19s\tremaining: 3m 25s\n",
      "81:\tlearn: 0.2745404\ttotal: 2m 21s\tremaining: 3m 23s\n",
      "82:\tlearn: 0.2736133\ttotal: 2m 23s\tremaining: 3m 21s\n",
      "83:\tlearn: 0.2727064\ttotal: 2m 24s\tremaining: 3m 20s\n",
      "84:\tlearn: 0.2718429\ttotal: 2m 26s\tremaining: 3m 18s\n",
      "85:\tlearn: 0.2709399\ttotal: 2m 28s\tremaining: 3m 16s\n",
      "86:\tlearn: 0.2701902\ttotal: 2m 29s\tremaining: 3m 14s\n",
      "87:\tlearn: 0.2691334\ttotal: 2m 31s\tremaining: 3m 12s\n",
      "88:\tlearn: 0.2681321\ttotal: 2m 33s\tremaining: 3m 10s\n",
      "89:\tlearn: 0.2670616\ttotal: 2m 34s\tremaining: 3m 9s\n",
      "90:\tlearn: 0.2662612\ttotal: 2m 36s\tremaining: 3m 7s\n",
      "91:\tlearn: 0.2653155\ttotal: 2m 38s\tremaining: 3m 5s\n",
      "92:\tlearn: 0.2644971\ttotal: 2m 39s\tremaining: 3m 3s\n",
      "93:\tlearn: 0.2640083\ttotal: 2m 41s\tremaining: 3m 1s\n",
      "94:\tlearn: 0.2634087\ttotal: 2m 42s\tremaining: 3m\n",
      "95:\tlearn: 0.2625669\ttotal: 2m 44s\tremaining: 2m 58s\n",
      "96:\tlearn: 0.2616989\ttotal: 2m 46s\tremaining: 2m 56s\n",
      "97:\tlearn: 0.2608323\ttotal: 2m 48s\tremaining: 2m 54s\n",
      "98:\tlearn: 0.2600837\ttotal: 2m 49s\tremaining: 2m 53s\n",
      "99:\tlearn: 0.2595496\ttotal: 2m 51s\tremaining: 2m 51s\n",
      "100:\tlearn: 0.2589796\ttotal: 2m 52s\tremaining: 2m 49s\n",
      "101:\tlearn: 0.2581054\ttotal: 2m 54s\tremaining: 2m 47s\n",
      "102:\tlearn: 0.2574389\ttotal: 2m 56s\tremaining: 2m 45s\n",
      "103:\tlearn: 0.2565851\ttotal: 2m 57s\tremaining: 2m 44s\n",
      "104:\tlearn: 0.2560606\ttotal: 2m 59s\tremaining: 2m 42s\n",
      "105:\tlearn: 0.2553221\ttotal: 3m 1s\tremaining: 2m 40s\n",
      "106:\tlearn: 0.2543699\ttotal: 3m 2s\tremaining: 2m 38s\n",
      "107:\tlearn: 0.2535416\ttotal: 3m 4s\tremaining: 2m 37s\n",
      "108:\tlearn: 0.2529722\ttotal: 3m 6s\tremaining: 2m 35s\n",
      "109:\tlearn: 0.2525321\ttotal: 3m 7s\tremaining: 2m 33s\n",
      "110:\tlearn: 0.2514423\ttotal: 3m 9s\tremaining: 2m 31s\n",
      "111:\tlearn: 0.2508231\ttotal: 3m 10s\tremaining: 2m 30s\n",
      "112:\tlearn: 0.2497679\ttotal: 3m 12s\tremaining: 2m 28s\n",
      "113:\tlearn: 0.2489620\ttotal: 3m 14s\tremaining: 2m 26s\n",
      "114:\tlearn: 0.2481036\ttotal: 3m 16s\tremaining: 2m 24s\n",
      "115:\tlearn: 0.2476729\ttotal: 3m 17s\tremaining: 2m 23s\n",
      "116:\tlearn: 0.2470596\ttotal: 3m 19s\tremaining: 2m 21s\n",
      "117:\tlearn: 0.2466472\ttotal: 3m 20s\tremaining: 2m 19s\n",
      "118:\tlearn: 0.2459175\ttotal: 3m 22s\tremaining: 2m 17s\n",
      "119:\tlearn: 0.2454938\ttotal: 3m 23s\tremaining: 2m 15s\n",
      "120:\tlearn: 0.2448188\ttotal: 3m 25s\tremaining: 2m 14s\n",
      "121:\tlearn: 0.2441269\ttotal: 3m 27s\tremaining: 2m 12s\n",
      "122:\tlearn: 0.2436520\ttotal: 3m 28s\tremaining: 2m 10s\n",
      "123:\tlearn: 0.2432759\ttotal: 3m 30s\tremaining: 2m 8s\n",
      "124:\tlearn: 0.2426274\ttotal: 3m 31s\tremaining: 2m 7s\n",
      "125:\tlearn: 0.2419400\ttotal: 3m 33s\tremaining: 2m 5s\n",
      "126:\tlearn: 0.2412242\ttotal: 3m 35s\tremaining: 2m 3s\n",
      "127:\tlearn: 0.2407560\ttotal: 3m 36s\tremaining: 2m 2s\n",
      "128:\tlearn: 0.2400726\ttotal: 3m 38s\tremaining: 2m\n",
      "129:\tlearn: 0.2397263\ttotal: 3m 40s\tremaining: 1m 58s\n",
      "130:\tlearn: 0.2392858\ttotal: 3m 41s\tremaining: 1m 56s\n",
      "131:\tlearn: 0.2387699\ttotal: 3m 43s\tremaining: 1m 55s\n",
      "132:\tlearn: 0.2382097\ttotal: 3m 45s\tremaining: 1m 53s\n",
      "133:\tlearn: 0.2371636\ttotal: 3m 46s\tremaining: 1m 51s\n",
      "134:\tlearn: 0.2367488\ttotal: 3m 48s\tremaining: 1m 49s\n",
      "135:\tlearn: 0.2363683\ttotal: 3m 50s\tremaining: 1m 48s\n",
      "136:\tlearn: 0.2360283\ttotal: 3m 51s\tremaining: 1m 46s\n",
      "137:\tlearn: 0.2356999\ttotal: 3m 53s\tremaining: 1m 44s\n",
      "138:\tlearn: 0.2350238\ttotal: 3m 54s\tremaining: 1m 43s\n",
      "139:\tlearn: 0.2344851\ttotal: 3m 56s\tremaining: 1m 41s\n",
      "140:\tlearn: 0.2336390\ttotal: 3m 58s\tremaining: 1m 39s\n",
      "141:\tlearn: 0.2330989\ttotal: 3m 59s\tremaining: 1m 37s\n",
      "142:\tlearn: 0.2327992\ttotal: 4m 1s\tremaining: 1m 36s\n",
      "143:\tlearn: 0.2325078\ttotal: 4m 2s\tremaining: 1m 34s\n",
      "144:\tlearn: 0.2320136\ttotal: 4m 4s\tremaining: 1m 32s\n",
      "145:\tlearn: 0.2314310\ttotal: 4m 6s\tremaining: 1m 31s\n",
      "146:\tlearn: 0.2309462\ttotal: 4m 7s\tremaining: 1m 29s\n",
      "147:\tlearn: 0.2302938\ttotal: 4m 9s\tremaining: 1m 27s\n",
      "148:\tlearn: 0.2298717\ttotal: 4m 10s\tremaining: 1m 25s\n",
      "149:\tlearn: 0.2295237\ttotal: 4m 12s\tremaining: 1m 24s\n",
      "150:\tlearn: 0.2291676\ttotal: 4m 14s\tremaining: 1m 22s\n",
      "151:\tlearn: 0.2286033\ttotal: 4m 15s\tremaining: 1m 20s\n",
      "152:\tlearn: 0.2283150\ttotal: 4m 17s\tremaining: 1m 19s\n",
      "153:\tlearn: 0.2271281\ttotal: 4m 18s\tremaining: 1m 17s\n",
      "154:\tlearn: 0.2263743\ttotal: 4m 20s\tremaining: 1m 15s\n",
      "155:\tlearn: 0.2260919\ttotal: 4m 22s\tremaining: 1m 13s\n",
      "156:\tlearn: 0.2252833\ttotal: 4m 23s\tremaining: 1m 12s\n",
      "157:\tlearn: 0.2248253\ttotal: 4m 25s\tremaining: 1m 10s\n",
      "158:\tlearn: 0.2244271\ttotal: 4m 26s\tremaining: 1m 8s\n",
      "159:\tlearn: 0.2238982\ttotal: 4m 28s\tremaining: 1m 7s\n",
      "160:\tlearn: 0.2232075\ttotal: 4m 30s\tremaining: 1m 5s\n",
      "161:\tlearn: 0.2227593\ttotal: 4m 31s\tremaining: 1m 3s\n",
      "162:\tlearn: 0.2225044\ttotal: 4m 33s\tremaining: 1m 2s\n",
      "163:\tlearn: 0.2219540\ttotal: 4m 34s\tremaining: 1m\n",
      "164:\tlearn: 0.2214308\ttotal: 4m 36s\tremaining: 58.7s\n",
      "165:\tlearn: 0.2211504\ttotal: 4m 38s\tremaining: 57s\n",
      "166:\tlearn: 0.2207551\ttotal: 4m 39s\tremaining: 55.3s\n",
      "167:\tlearn: 0.2199405\ttotal: 4m 41s\tremaining: 53.6s\n",
      "168:\tlearn: 0.2192324\ttotal: 4m 43s\tremaining: 52s\n",
      "169:\tlearn: 0.2189768\ttotal: 4m 44s\tremaining: 50.3s\n",
      "170:\tlearn: 0.2186971\ttotal: 4m 46s\tremaining: 48.6s\n",
      "171:\tlearn: 0.2184555\ttotal: 4m 47s\tremaining: 46.9s\n",
      "172:\tlearn: 0.2178961\ttotal: 4m 49s\tremaining: 45.2s\n",
      "173:\tlearn: 0.2173718\ttotal: 4m 51s\tremaining: 43.5s\n",
      "174:\tlearn: 0.2170222\ttotal: 4m 52s\tremaining: 41.8s\n",
      "175:\tlearn: 0.2167828\ttotal: 4m 54s\tremaining: 40.2s\n",
      "176:\tlearn: 0.2163480\ttotal: 4m 56s\tremaining: 38.5s\n",
      "177:\tlearn: 0.2158956\ttotal: 4m 57s\tremaining: 36.8s\n",
      "178:\tlearn: 0.2153834\ttotal: 4m 59s\tremaining: 35.1s\n",
      "179:\tlearn: 0.2150898\ttotal: 5m\tremaining: 33.4s\n",
      "180:\tlearn: 0.2145844\ttotal: 5m 2s\tremaining: 31.8s\n",
      "181:\tlearn: 0.2141628\ttotal: 5m 4s\tremaining: 30.1s\n",
      "182:\tlearn: 0.2138103\ttotal: 5m 5s\tremaining: 28.4s\n",
      "183:\tlearn: 0.2133337\ttotal: 5m 7s\tremaining: 26.7s\n",
      "184:\tlearn: 0.2131072\ttotal: 5m 9s\tremaining: 25.1s\n",
      "185:\tlearn: 0.2126570\ttotal: 5m 10s\tremaining: 23.4s\n",
      "186:\tlearn: 0.2124303\ttotal: 5m 12s\tremaining: 21.7s\n",
      "187:\tlearn: 0.2121159\ttotal: 5m 13s\tremaining: 20s\n",
      "188:\tlearn: 0.2118803\ttotal: 5m 15s\tremaining: 18.4s\n",
      "189:\tlearn: 0.2116482\ttotal: 5m 16s\tremaining: 16.7s\n",
      "190:\tlearn: 0.2114341\ttotal: 5m 18s\tremaining: 15s\n",
      "191:\tlearn: 0.2108678\ttotal: 5m 20s\tremaining: 13.3s\n",
      "192:\tlearn: 0.2103746\ttotal: 5m 21s\tremaining: 11.7s\n",
      "193:\tlearn: 0.2101566\ttotal: 5m 23s\tremaining: 10s\n",
      "194:\tlearn: 0.2094660\ttotal: 5m 25s\tremaining: 8.34s\n",
      "195:\tlearn: 0.2086807\ttotal: 5m 27s\tremaining: 6.67s\n",
      "196:\tlearn: 0.2082542\ttotal: 5m 28s\tremaining: 5.01s\n",
      "197:\tlearn: 0.2078670\ttotal: 5m 30s\tremaining: 3.34s\n",
      "198:\tlearn: 0.2073246\ttotal: 5m 31s\tremaining: 1.67s\n",
      "199:\tlearn: 0.2066266\ttotal: 5m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb2f2ef2a90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid_CBC = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.287155\n",
      "0:\tlearn: 0.5847555\ttotal: 2.02s\tremaining: 6m 42s\n",
      "1:\tlearn: 0.5417580\ttotal: 4.21s\tremaining: 6m 56s\n",
      "2:\tlearn: 0.5231790\ttotal: 6.26s\tremaining: 6m 51s\n",
      "3:\tlearn: 0.5069022\ttotal: 8.36s\tremaining: 6m 49s\n",
      "4:\tlearn: 0.4870916\ttotal: 10.4s\tremaining: 6m 44s\n",
      "5:\tlearn: 0.4759710\ttotal: 12.4s\tremaining: 6m 41s\n",
      "6:\tlearn: 0.4637252\ttotal: 14.4s\tremaining: 6m 38s\n",
      "7:\tlearn: 0.4555633\ttotal: 16.5s\tremaining: 6m 35s\n",
      "8:\tlearn: 0.4483392\ttotal: 18.5s\tremaining: 6m 32s\n",
      "9:\tlearn: 0.4398245\ttotal: 20.5s\tremaining: 6m 29s\n",
      "10:\tlearn: 0.4304193\ttotal: 22.5s\tremaining: 6m 26s\n",
      "11:\tlearn: 0.4247101\ttotal: 24.5s\tremaining: 6m 23s\n",
      "12:\tlearn: 0.4192139\ttotal: 26.5s\tremaining: 6m 21s\n",
      "13:\tlearn: 0.4146895\ttotal: 28.5s\tremaining: 6m 18s\n",
      "14:\tlearn: 0.4106842\ttotal: 30.5s\tremaining: 6m 16s\n",
      "15:\tlearn: 0.4071163\ttotal: 32.6s\tremaining: 6m 15s\n",
      "16:\tlearn: 0.4036746\ttotal: 34.7s\tremaining: 6m 13s\n",
      "17:\tlearn: 0.3990275\ttotal: 36.8s\tremaining: 6m 12s\n",
      "18:\tlearn: 0.3958303\ttotal: 38.9s\tremaining: 6m 10s\n",
      "19:\tlearn: 0.3913693\ttotal: 41s\tremaining: 6m 9s\n",
      "20:\tlearn: 0.3881798\ttotal: 43.2s\tremaining: 6m 7s\n",
      "21:\tlearn: 0.3850276\ttotal: 45.2s\tremaining: 6m 6s\n",
      "22:\tlearn: 0.3818907\ttotal: 47.4s\tremaining: 6m 4s\n",
      "23:\tlearn: 0.3797794\ttotal: 49.5s\tremaining: 6m 2s\n",
      "24:\tlearn: 0.3774870\ttotal: 51.5s\tremaining: 6m\n",
      "25:\tlearn: 0.3754686\ttotal: 53.5s\tremaining: 5m 58s\n",
      "26:\tlearn: 0.3721409\ttotal: 55.5s\tremaining: 5m 55s\n",
      "27:\tlearn: 0.3691675\ttotal: 57.6s\tremaining: 5m 53s\n",
      "28:\tlearn: 0.3664590\ttotal: 59.6s\tremaining: 5m 51s\n",
      "29:\tlearn: 0.3643381\ttotal: 1m 1s\tremaining: 5m 49s\n",
      "30:\tlearn: 0.3627981\ttotal: 1m 3s\tremaining: 5m 46s\n",
      "31:\tlearn: 0.3595782\ttotal: 1m 5s\tremaining: 5m 44s\n",
      "32:\tlearn: 0.3576733\ttotal: 1m 7s\tremaining: 5m 42s\n",
      "33:\tlearn: 0.3552960\ttotal: 1m 9s\tremaining: 5m 39s\n",
      "34:\tlearn: 0.3530141\ttotal: 1m 11s\tremaining: 5m 37s\n",
      "35:\tlearn: 0.3509888\ttotal: 1m 13s\tremaining: 5m 35s\n",
      "36:\tlearn: 0.3495625\ttotal: 1m 15s\tremaining: 5m 33s\n",
      "37:\tlearn: 0.3480337\ttotal: 1m 17s\tremaining: 5m 31s\n",
      "38:\tlearn: 0.3459510\ttotal: 1m 19s\tremaining: 5m 29s\n",
      "39:\tlearn: 0.3442086\ttotal: 1m 21s\tremaining: 5m 26s\n",
      "40:\tlearn: 0.3421151\ttotal: 1m 23s\tremaining: 5m 24s\n",
      "41:\tlearn: 0.3400959\ttotal: 1m 25s\tremaining: 5m 21s\n",
      "42:\tlearn: 0.3372722\ttotal: 1m 27s\tremaining: 5m 19s\n",
      "43:\tlearn: 0.3356619\ttotal: 1m 29s\tremaining: 5m 17s\n",
      "44:\tlearn: 0.3316528\ttotal: 1m 31s\tremaining: 5m 15s\n",
      "45:\tlearn: 0.3299619\ttotal: 1m 33s\tremaining: 5m 13s\n",
      "46:\tlearn: 0.3283608\ttotal: 1m 35s\tremaining: 5m 10s\n",
      "47:\tlearn: 0.3266986\ttotal: 1m 37s\tremaining: 5m 9s\n",
      "48:\tlearn: 0.3247716\ttotal: 1m 39s\tremaining: 5m 7s\n",
      "49:\tlearn: 0.3230842\ttotal: 1m 41s\tremaining: 5m 5s\n",
      "50:\tlearn: 0.3215879\ttotal: 1m 43s\tremaining: 5m 3s\n",
      "51:\tlearn: 0.3199417\ttotal: 1m 45s\tremaining: 5m 1s\n",
      "52:\tlearn: 0.3180289\ttotal: 1m 47s\tremaining: 4m 59s\n",
      "53:\tlearn: 0.3162774\ttotal: 1m 49s\tremaining: 4m 57s\n",
      "54:\tlearn: 0.3147962\ttotal: 1m 51s\tremaining: 4m 55s\n",
      "55:\tlearn: 0.3129331\ttotal: 1m 53s\tremaining: 4m 53s\n",
      "56:\tlearn: 0.3119283\ttotal: 1m 55s\tremaining: 4m 50s\n",
      "57:\tlearn: 0.3102946\ttotal: 1m 57s\tremaining: 4m 48s\n",
      "58:\tlearn: 0.3086721\ttotal: 1m 59s\tremaining: 4m 46s\n",
      "59:\tlearn: 0.3070181\ttotal: 2m 1s\tremaining: 4m 44s\n",
      "60:\tlearn: 0.3056770\ttotal: 2m 3s\tremaining: 4m 42s\n",
      "61:\tlearn: 0.3041631\ttotal: 2m 5s\tremaining: 4m 40s\n",
      "62:\tlearn: 0.3027179\ttotal: 2m 7s\tremaining: 4m 38s\n",
      "102:\tlearn: 0.2620386\ttotal: 3m 27s\tremaining: 3m 14s\n",
      "103:\tlearn: 0.2613383\ttotal: 3m 28s\tremaining: 3m 12s\n",
      "104:\tlearn: 0.2604117\ttotal: 3m 30s\tremaining: 3m 10s\n",
      "105:\tlearn: 0.2591385\ttotal: 3m 33s\tremaining: 3m 9s\n",
      "106:\tlearn: 0.2579717\ttotal: 3m 35s\tremaining: 3m 7s\n",
      "107:\tlearn: 0.2572813\ttotal: 3m 37s\tremaining: 3m 5s\n",
      "108:\tlearn: 0.2568172\ttotal: 3m 39s\tremaining: 3m 2s\n",
      "109:\tlearn: 0.2562161\ttotal: 3m 41s\tremaining: 3m\n",
      "110:\tlearn: 0.2557650\ttotal: 3m 43s\tremaining: 2m 58s\n",
      "111:\tlearn: 0.2549218\ttotal: 3m 45s\tremaining: 2m 56s\n",
      "112:\tlearn: 0.2543599\ttotal: 3m 47s\tremaining: 2m 54s\n",
      "113:\tlearn: 0.2537985\ttotal: 3m 49s\tremaining: 2m 52s\n",
      "114:\tlearn: 0.2529596\ttotal: 3m 51s\tremaining: 2m 50s\n",
      "115:\tlearn: 0.2524505\ttotal: 3m 53s\tremaining: 2m 48s\n",
      "116:\tlearn: 0.2519267\ttotal: 3m 55s\tremaining: 2m 46s\n",
      "117:\tlearn: 0.2510988\ttotal: 3m 57s\tremaining: 2m 44s\n",
      "118:\tlearn: 0.2499641\ttotal: 3m 59s\tremaining: 2m 42s\n",
      "119:\tlearn: 0.2492441\ttotal: 4m 1s\tremaining: 2m 40s\n",
      "120:\tlearn: 0.2487920\ttotal: 4m 2s\tremaining: 2m 38s\n",
      "121:\tlearn: 0.2483782\ttotal: 4m 4s\tremaining: 2m 36s\n",
      "122:\tlearn: 0.2475183\ttotal: 4m 6s\tremaining: 2m 34s\n",
      "123:\tlearn: 0.2469509\ttotal: 4m 8s\tremaining: 2m 32s\n",
      "124:\tlearn: 0.2458777\ttotal: 4m 10s\tremaining: 2m 30s\n",
      "125:\tlearn: 0.2452212\ttotal: 4m 12s\tremaining: 2m 28s\n",
      "126:\tlearn: 0.2440420\ttotal: 4m 14s\tremaining: 2m 26s\n",
      "127:\tlearn: 0.2436451\ttotal: 4m 16s\tremaining: 2m 24s\n",
      "128:\tlearn: 0.2431106\ttotal: 4m 18s\tremaining: 2m 22s\n",
      "129:\tlearn: 0.2422574\ttotal: 4m 20s\tremaining: 2m 20s\n",
      "130:\tlearn: 0.2417102\ttotal: 4m 22s\tremaining: 2m 18s\n",
      "131:\tlearn: 0.2411657\ttotal: 4m 24s\tremaining: 2m 16s\n",
      "132:\tlearn: 0.2407119\ttotal: 4m 26s\tremaining: 2m 14s\n",
      "133:\tlearn: 0.2403706\ttotal: 4m 28s\tremaining: 2m 12s\n",
      "134:\tlearn: 0.2399515\ttotal: 4m 29s\tremaining: 2m 9s\n",
      "135:\tlearn: 0.2391750\ttotal: 4m 31s\tremaining: 2m 7s\n",
      "136:\tlearn: 0.2385045\ttotal: 4m 34s\tremaining: 2m 6s\n",
      "137:\tlearn: 0.2378830\ttotal: 4m 36s\tremaining: 2m 4s\n",
      "138:\tlearn: 0.2374528\ttotal: 4m 37s\tremaining: 2m 1s\n",
      "139:\tlearn: 0.2369509\ttotal: 4m 39s\tremaining: 1m 59s\n",
      "140:\tlearn: 0.2364490\ttotal: 4m 41s\tremaining: 1m 57s\n",
      "141:\tlearn: 0.2361371\ttotal: 4m 43s\tremaining: 1m 55s\n",
      "142:\tlearn: 0.2355209\ttotal: 4m 45s\tremaining: 1m 53s\n",
      "143:\tlearn: 0.2351406\ttotal: 4m 47s\tremaining: 1m 51s\n",
      "144:\tlearn: 0.2347204\ttotal: 4m 49s\tremaining: 1m 49s\n",
      "145:\tlearn: 0.2341470\ttotal: 4m 51s\tremaining: 1m 47s\n",
      "146:\tlearn: 0.2334329\ttotal: 4m 53s\tremaining: 1m 45s\n",
      "147:\tlearn: 0.2330284\ttotal: 4m 55s\tremaining: 1m 43s\n",
      "148:\tlearn: 0.2324650\ttotal: 4m 57s\tremaining: 1m 41s\n",
      "149:\tlearn: 0.2320922\ttotal: 4m 59s\tremaining: 1m 39s\n",
      "150:\tlearn: 0.2314468\ttotal: 5m 1s\tremaining: 1m 37s\n",
      "151:\tlearn: 0.2303984\ttotal: 5m 3s\tremaining: 1m 35s\n",
      "152:\tlearn: 0.2294668\ttotal: 5m 5s\tremaining: 1m 33s\n",
      "153:\tlearn: 0.2288822\ttotal: 5m 7s\tremaining: 1m 31s\n",
      "154:\tlearn: 0.2279078\ttotal: 5m 9s\tremaining: 1m 29s\n",
      "155:\tlearn: 0.2276034\ttotal: 5m 10s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.2267925\ttotal: 5m 12s\tremaining: 1m 25s\n",
      "157:\tlearn: 0.2264743\ttotal: 5m 14s\tremaining: 1m 23s\n",
      "158:\tlearn: 0.2260022\ttotal: 5m 16s\tremaining: 1m 21s\n",
      "159:\tlearn: 0.2253687\ttotal: 5m 18s\tremaining: 1m 19s\n",
      "160:\tlearn: 0.2248240\ttotal: 5m 20s\tremaining: 1m 17s\n",
      "161:\tlearn: 0.2242789\ttotal: 5m 22s\tremaining: 1m 15s\n",
      "162:\tlearn: 0.2239988\ttotal: 5m 24s\tremaining: 1m 13s\n",
      "163:\tlearn: 0.2234818\ttotal: 5m 26s\tremaining: 1m 11s\n",
      "164:\tlearn: 0.2231271\ttotal: 5m 28s\tremaining: 1m 9s\n",
      "165:\tlearn: 0.2228495\ttotal: 5m 30s\tremaining: 1m 7s\n",
      "166:\tlearn: 0.2220885\ttotal: 5m 32s\tremaining: 1m 5s\n",
      "167:\tlearn: 0.2216321\ttotal: 5m 34s\tremaining: 1m 3s\n",
      "168:\tlearn: 0.2209362\ttotal: 5m 36s\tremaining: 1m 1s\n",
      "169:\tlearn: 0.2205822\ttotal: 5m 38s\tremaining: 59.7s\n",
      "170:\tlearn: 0.2201204\ttotal: 5m 40s\tremaining: 57.7s\n",
      "171:\tlearn: 0.2196362\ttotal: 5m 42s\tremaining: 55.7s\n",
      "172:\tlearn: 0.2192978\ttotal: 5m 44s\tremaining: 53.7s\n",
      "173:\tlearn: 0.2190466\ttotal: 5m 46s\tremaining: 51.7s\n",
      "174:\tlearn: 0.2186326\ttotal: 5m 48s\tremaining: 49.7s\n",
      "175:\tlearn: 0.2183326\ttotal: 5m 49s\tremaining: 47.7s\n",
      "176:\tlearn: 0.2180757\ttotal: 5m 51s\tremaining: 45.7s\n",
      "177:\tlearn: 0.2177915\ttotal: 5m 53s\tremaining: 43.7s\n",
      "178:\tlearn: 0.2172487\ttotal: 5m 55s\tremaining: 41.7s\n",
      "179:\tlearn: 0.2170036\ttotal: 5m 57s\tremaining: 39.7s\n",
      "180:\tlearn: 0.2163488\ttotal: 5m 59s\tremaining: 37.7s\n",
      "181:\tlearn: 0.2158689\ttotal: 6m 1s\tremaining: 35.7s\n",
      "182:\tlearn: 0.2152593\ttotal: 6m 3s\tremaining: 33.7s\n",
      "183:\tlearn: 0.2149094\ttotal: 6m 5s\tremaining: 31.8s\n",
      "184:\tlearn: 0.2144226\ttotal: 6m 7s\tremaining: 29.8s\n",
      "185:\tlearn: 0.2141783\ttotal: 6m 9s\tremaining: 27.8s\n",
      "186:\tlearn: 0.2135533\ttotal: 6m 11s\tremaining: 25.8s\n",
      "187:\tlearn: 0.2132565\ttotal: 6m 12s\tremaining: 23.8s\n",
      "188:\tlearn: 0.2126891\ttotal: 6m 14s\tremaining: 21.8s\n",
      "189:\tlearn: 0.2122436\ttotal: 6m 16s\tremaining: 19.8s\n",
      "190:\tlearn: 0.2120088\ttotal: 6m 18s\tremaining: 17.9s\n",
      "191:\tlearn: 0.2116080\ttotal: 6m 20s\tremaining: 15.9s\n",
      "192:\tlearn: 0.2113860\ttotal: 6m 22s\tremaining: 13.9s\n",
      "193:\tlearn: 0.2108620\ttotal: 6m 24s\tremaining: 11.9s\n",
      "194:\tlearn: 0.2106379\ttotal: 6m 26s\tremaining: 9.91s\n",
      "195:\tlearn: 0.2104079\ttotal: 6m 28s\tremaining: 7.93s\n",
      "196:\tlearn: 0.2101316\ttotal: 6m 30s\tremaining: 5.95s\n",
      "197:\tlearn: 0.2097341\ttotal: 6m 32s\tremaining: 3.96s\n",
      "198:\tlearn: 0.2093148\ttotal: 6m 34s\tremaining: 1.98s\n",
      "199:\tlearn: 0.2089557\ttotal: 6m 36s\tremaining: 0us\n",
      "Learning rate set to 0.287155\n",
      "0:\tlearn: 0.5885272\ttotal: 2.01s\tremaining: 6m 40s\n",
      "1:\tlearn: 0.5464204\ttotal: 4.09s\tremaining: 6m 44s\n",
      "2:\tlearn: 0.5253196\ttotal: 6.13s\tremaining: 6m 42s\n",
      "3:\tlearn: 0.5053435\ttotal: 8.12s\tremaining: 6m 38s\n",
      "4:\tlearn: 0.4898538\ttotal: 10.1s\tremaining: 6m 35s\n",
      "5:\tlearn: 0.4790069\ttotal: 12.2s\tremaining: 6m 32s\n",
      "6:\tlearn: 0.4668418\ttotal: 14.2s\tremaining: 6m 31s\n",
      "7:\tlearn: 0.4586541\ttotal: 16.2s\tremaining: 6m 28s\n",
      "8:\tlearn: 0.4501494\ttotal: 18.2s\tremaining: 6m 25s\n",
      "9:\tlearn: 0.4425989\ttotal: 20.2s\tremaining: 6m 23s\n",
      "10:\tlearn: 0.4355131\ttotal: 22.2s\tremaining: 6m 21s\n",
      "11:\tlearn: 0.4291730\ttotal: 24.3s\tremaining: 6m 19s\n",
      "12:\tlearn: 0.4239658\ttotal: 26.2s\tremaining: 6m 17s\n",
      "13:\tlearn: 0.4199441\ttotal: 28.2s\tremaining: 6m 14s\n",
      "14:\tlearn: 0.4135354\ttotal: 30.1s\tremaining: 6m 11s\n",
      "15:\tlearn: 0.4100763\ttotal: 32.2s\tremaining: 6m 10s\n",
      "16:\tlearn: 0.4063715\ttotal: 34.3s\tremaining: 6m 8s\n",
      "17:\tlearn: 0.4027530\ttotal: 36.3s\tremaining: 6m 6s\n",
      "18:\tlearn: 0.3994042\ttotal: 38.3s\tremaining: 6m 5s\n",
      "19:\tlearn: 0.3954761\ttotal: 40.3s\tremaining: 6m 2s\n",
      "20:\tlearn: 0.3918783\ttotal: 42.4s\tremaining: 6m 1s\n",
      "21:\tlearn: 0.3884335\ttotal: 44.4s\tremaining: 5m 59s\n",
      "22:\tlearn: 0.3859710\ttotal: 46.5s\tremaining: 5m 57s\n",
      "23:\tlearn: 0.3816499\ttotal: 48.5s\tremaining: 5m 55s\n",
      "24:\tlearn: 0.3793002\ttotal: 50.5s\tremaining: 5m 53s\n",
      "25:\tlearn: 0.3763881\ttotal: 52.6s\tremaining: 5m 51s\n",
      "26:\tlearn: 0.3738586\ttotal: 54.6s\tremaining: 5m 50s\n",
      "27:\tlearn: 0.3714488\ttotal: 56.6s\tremaining: 5m 47s\n",
      "28:\tlearn: 0.3681459\ttotal: 58.6s\tremaining: 5m 45s\n",
      "29:\tlearn: 0.3661846\ttotal: 1m\tremaining: 5m 43s\n",
      "30:\tlearn: 0.3634402\ttotal: 1m 2s\tremaining: 5m 41s\n",
      "31:\tlearn: 0.3614073\ttotal: 1m 4s\tremaining: 5m 38s\n",
      "32:\tlearn: 0.3592712\ttotal: 1m 6s\tremaining: 5m 36s\n",
      "33:\tlearn: 0.3570673\ttotal: 1m 8s\tremaining: 5m 34s\n",
      "34:\tlearn: 0.3547722\ttotal: 1m 10s\tremaining: 5m 32s\n",
      "35:\tlearn: 0.3524275\ttotal: 1m 12s\tremaining: 5m 29s\n",
      "36:\tlearn: 0.3503320\ttotal: 1m 14s\tremaining: 5m 27s\n",
      "37:\tlearn: 0.3483695\ttotal: 1m 16s\tremaining: 5m 25s\n",
      "38:\tlearn: 0.3465009\ttotal: 1m 18s\tremaining: 5m 22s\n",
      "39:\tlearn: 0.3444775\ttotal: 1m 20s\tremaining: 5m 20s\n",
      "40:\tlearn: 0.3412985\ttotal: 1m 21s\tremaining: 5m 17s\n",
      "41:\tlearn: 0.3379608\ttotal: 1m 23s\tremaining: 5m 15s\n",
      "42:\tlearn: 0.3361540\ttotal: 1m 25s\tremaining: 5m 13s\n",
      "43:\tlearn: 0.3342811\ttotal: 1m 27s\tremaining: 5m 11s\n",
      "44:\tlearn: 0.3326036\ttotal: 1m 29s\tremaining: 5m 9s\n",
      "45:\tlearn: 0.3308964\ttotal: 1m 31s\tremaining: 5m 7s\n",
      "46:\tlearn: 0.3290428\ttotal: 1m 33s\tremaining: 5m 5s\n",
      "47:\tlearn: 0.3273844\ttotal: 1m 35s\tremaining: 5m 3s\n",
      "48:\tlearn: 0.3250999\ttotal: 1m 37s\tremaining: 5m 1s\n",
      "49:\tlearn: 0.3229346\ttotal: 1m 39s\tremaining: 4m 59s\n",
      "50:\tlearn: 0.3195605\ttotal: 1m 41s\tremaining: 4m 57s\n",
      "51:\tlearn: 0.3180901\ttotal: 1m 43s\tremaining: 4m 55s\n",
      "52:\tlearn: 0.3164082\ttotal: 1m 45s\tremaining: 4m 53s\n",
      "53:\tlearn: 0.3146542\ttotal: 1m 47s\tremaining: 4m 51s\n",
      "54:\tlearn: 0.3128268\ttotal: 1m 49s\tremaining: 4m 49s\n",
      "55:\tlearn: 0.3112462\ttotal: 1m 51s\tremaining: 4m 47s\n",
      "56:\tlearn: 0.3098297\ttotal: 1m 53s\tremaining: 4m 45s\n",
      "57:\tlearn: 0.3082332\ttotal: 1m 55s\tremaining: 4m 43s\n",
      "58:\tlearn: 0.3068845\ttotal: 1m 57s\tremaining: 4m 41s\n",
      "59:\tlearn: 0.3057133\ttotal: 1m 59s\tremaining: 4m 39s\n",
      "60:\tlearn: 0.3041253\ttotal: 2m 1s\tremaining: 4m 37s\n",
      "61:\tlearn: 0.3028552\ttotal: 2m 3s\tremaining: 4m 35s\n",
      "62:\tlearn: 0.3014798\ttotal: 2m 5s\tremaining: 4m 33s\n",
      "63:\tlearn: 0.3001505\ttotal: 2m 7s\tremaining: 4m 31s\n",
      "64:\tlearn: 0.2988854\ttotal: 2m 9s\tremaining: 4m 29s\n",
      "65:\tlearn: 0.2978248\ttotal: 2m 11s\tremaining: 4m 27s\n",
      "66:\tlearn: 0.2967598\ttotal: 2m 13s\tremaining: 4m 25s\n",
      "67:\tlearn: 0.2954075\ttotal: 2m 15s\tremaining: 4m 23s\n",
      "68:\tlearn: 0.2941450\ttotal: 2m 17s\tremaining: 4m 20s\n",
      "69:\tlearn: 0.2930718\ttotal: 2m 19s\tremaining: 4m 18s\n",
      "70:\tlearn: 0.2918713\ttotal: 2m 21s\tremaining: 4m 16s\n",
      "71:\tlearn: 0.2907847\ttotal: 2m 23s\tremaining: 4m 14s\n",
      "72:\tlearn: 0.2895728\ttotal: 2m 25s\tremaining: 4m 12s\n",
      "73:\tlearn: 0.2883072\ttotal: 2m 27s\tremaining: 4m 10s\n",
      "74:\tlearn: 0.2875348\ttotal: 2m 29s\tremaining: 4m 8s\n",
      "75:\tlearn: 0.2859515\ttotal: 2m 31s\tremaining: 4m 6s\n",
      "76:\tlearn: 0.2846895\ttotal: 2m 33s\tremaining: 4m 4s\n",
      "77:\tlearn: 0.2835940\ttotal: 2m 35s\tremaining: 4m 2s\n",
      "78:\tlearn: 0.2826255\ttotal: 2m 37s\tremaining: 4m\n",
      "79:\tlearn: 0.2816964\ttotal: 2m 39s\tremaining: 3m 58s\n",
      "80:\tlearn: 0.2801371\ttotal: 2m 41s\tremaining: 3m 56s\n",
      "81:\tlearn: 0.2790039\ttotal: 2m 43s\tremaining: 3m 54s\n",
      "82:\tlearn: 0.2780730\ttotal: 2m 45s\tremaining: 3m 52s\n",
      "83:\tlearn: 0.2769994\ttotal: 2m 47s\tremaining: 3m 50s\n",
      "84:\tlearn: 0.2759874\ttotal: 2m 49s\tremaining: 3m 48s\n",
      "85:\tlearn: 0.2750406\ttotal: 2m 51s\tremaining: 3m 47s\n",
      "86:\tlearn: 0.2740872\ttotal: 2m 53s\tremaining: 3m 45s\n",
      "87:\tlearn: 0.2731935\ttotal: 2m 55s\tremaining: 3m 43s\n",
      "88:\tlearn: 0.2724224\ttotal: 2m 57s\tremaining: 3m 41s\n",
      "89:\tlearn: 0.2716483\ttotal: 2m 59s\tremaining: 3m 39s\n",
      "90:\tlearn: 0.2709084\ttotal: 3m 1s\tremaining: 3m 36s\n",
      "91:\tlearn: 0.2702148\ttotal: 3m 3s\tremaining: 3m 34s\n",
      "92:\tlearn: 0.2689790\ttotal: 3m 4s\tremaining: 3m 32s\n",
      "93:\tlearn: 0.2683181\ttotal: 3m 6s\tremaining: 3m 30s\n",
      "94:\tlearn: 0.2672747\ttotal: 3m 8s\tremaining: 3m 28s\n",
      "95:\tlearn: 0.2664574\ttotal: 3m 10s\tremaining: 3m 26s\n",
      "96:\tlearn: 0.2658328\ttotal: 3m 12s\tremaining: 3m 24s\n",
      "97:\tlearn: 0.2649790\ttotal: 3m 14s\tremaining: 3m 22s\n",
      "98:\tlearn: 0.2640061\ttotal: 3m 16s\tremaining: 3m 20s\n",
      "99:\tlearn: 0.2630407\ttotal: 3m 18s\tremaining: 3m 18s\n",
      "100:\tlearn: 0.2618192\ttotal: 3m 20s\tremaining: 3m 16s\n",
      "101:\tlearn: 0.2611966\ttotal: 3m 22s\tremaining: 3m 14s\n",
      "102:\tlearn: 0.2603609\ttotal: 3m 24s\tremaining: 3m 12s\n",
      "103:\tlearn: 0.2598202\ttotal: 3m 26s\tremaining: 3m 10s\n",
      "104:\tlearn: 0.2590436\ttotal: 3m 27s\tremaining: 3m 8s\n",
      "105:\tlearn: 0.2575321\ttotal: 3m 29s\tremaining: 3m 6s\n",
      "106:\tlearn: 0.2567326\ttotal: 3m 31s\tremaining: 3m 4s\n",
      "107:\tlearn: 0.2560387\ttotal: 3m 33s\tremaining: 3m 2s\n",
      "108:\tlearn: 0.2551020\ttotal: 3m 35s\tremaining: 3m\n",
      "109:\tlearn: 0.2546169\ttotal: 3m 37s\tremaining: 2m 58s\n",
      "110:\tlearn: 0.2537904\ttotal: 3m 39s\tremaining: 2m 56s\n",
      "111:\tlearn: 0.2530378\ttotal: 3m 41s\tremaining: 2m 54s\n",
      "112:\tlearn: 0.2522973\ttotal: 3m 43s\tremaining: 2m 52s\n",
      "113:\tlearn: 0.2518495\ttotal: 3m 45s\tremaining: 2m 50s\n",
      "114:\tlearn: 0.2507620\ttotal: 3m 47s\tremaining: 2m 48s\n",
      "115:\tlearn: 0.2502370\ttotal: 3m 49s\tremaining: 2m 46s\n",
      "116:\tlearn: 0.2498113\ttotal: 3m 51s\tremaining: 2m 44s\n",
      "117:\tlearn: 0.2490319\ttotal: 3m 53s\tremaining: 2m 42s\n",
      "118:\tlearn: 0.2484141\ttotal: 3m 55s\tremaining: 2m 40s\n",
      "119:\tlearn: 0.2478068\ttotal: 3m 57s\tremaining: 2m 38s\n",
      "120:\tlearn: 0.2471164\ttotal: 3m 59s\tremaining: 2m 36s\n",
      "121:\tlearn: 0.2467347\ttotal: 4m 1s\tremaining: 2m 34s\n",
      "122:\tlearn: 0.2460162\ttotal: 4m 3s\tremaining: 2m 32s\n",
      "123:\tlearn: 0.2451784\ttotal: 4m 5s\tremaining: 2m 30s\n",
      "124:\tlearn: 0.2445507\ttotal: 4m 7s\tremaining: 2m 28s\n",
      "125:\tlearn: 0.2441219\ttotal: 4m 8s\tremaining: 2m 26s\n",
      "126:\tlearn: 0.2434073\ttotal: 4m 10s\tremaining: 2m 24s\n",
      "127:\tlearn: 0.2427890\ttotal: 4m 12s\tremaining: 2m 22s\n",
      "128:\tlearn: 0.2422281\ttotal: 4m 14s\tremaining: 2m 20s\n",
      "129:\tlearn: 0.2416021\ttotal: 4m 16s\tremaining: 2m 18s\n",
      "130:\tlearn: 0.2411026\ttotal: 4m 18s\tremaining: 2m 16s\n",
      "131:\tlearn: 0.2407410\ttotal: 4m 20s\tremaining: 2m 14s\n",
      "132:\tlearn: 0.2400530\ttotal: 4m 22s\tremaining: 2m 12s\n",
      "133:\tlearn: 0.2397504\ttotal: 4m 24s\tremaining: 2m 10s\n",
      "134:\tlearn: 0.2391744\ttotal: 4m 26s\tremaining: 2m 8s\n",
      "135:\tlearn: 0.2387245\ttotal: 4m 28s\tremaining: 2m 6s\n",
      "136:\tlearn: 0.2381353\ttotal: 4m 29s\tremaining: 2m 4s\n",
      "137:\tlearn: 0.2374155\ttotal: 4m 31s\tremaining: 2m 2s\n",
      "138:\tlearn: 0.2365468\ttotal: 4m 33s\tremaining: 2m\n",
      "139:\tlearn: 0.2358492\ttotal: 4m 35s\tremaining: 1m 58s\n",
      "140:\tlearn: 0.2346484\ttotal: 4m 37s\tremaining: 1m 56s\n",
      "141:\tlearn: 0.2340177\ttotal: 4m 39s\tremaining: 1m 54s\n",
      "142:\tlearn: 0.2335104\ttotal: 4m 41s\tremaining: 1m 52s\n",
      "143:\tlearn: 0.2328897\ttotal: 4m 43s\tremaining: 1m 50s\n",
      "144:\tlearn: 0.2322936\ttotal: 4m 45s\tremaining: 1m 48s\n",
      "145:\tlearn: 0.2319652\ttotal: 4m 47s\tremaining: 1m 46s\n",
      "146:\tlearn: 0.2316030\ttotal: 4m 49s\tremaining: 1m 44s\n",
      "147:\tlearn: 0.2309742\ttotal: 4m 51s\tremaining: 1m 42s\n",
      "148:\tlearn: 0.2305744\ttotal: 4m 53s\tremaining: 1m 40s\n",
      "149:\tlearn: 0.2302692\ttotal: 4m 55s\tremaining: 1m 38s\n",
      "150:\tlearn: 0.2292962\ttotal: 4m 57s\tremaining: 1m 36s\n",
      "151:\tlearn: 0.2287905\ttotal: 4m 59s\tremaining: 1m 34s\n",
      "152:\tlearn: 0.2283387\ttotal: 5m 1s\tremaining: 1m 32s\n",
      "153:\tlearn: 0.2278436\ttotal: 5m 3s\tremaining: 1m 30s\n",
      "154:\tlearn: 0.2271609\ttotal: 5m 5s\tremaining: 1m 28s\n",
      "155:\tlearn: 0.2266226\ttotal: 5m 7s\tremaining: 1m 26s\n",
      "156:\tlearn: 0.2263307\ttotal: 5m 9s\tremaining: 1m 24s\n",
      "157:\tlearn: 0.2257820\ttotal: 5m 11s\tremaining: 1m 22s\n",
      "158:\tlearn: 0.2251852\ttotal: 5m 13s\tremaining: 1m 20s\n",
      "159:\tlearn: 0.2248563\ttotal: 5m 15s\tremaining: 1m 18s\n",
      "160:\tlearn: 0.2242078\ttotal: 5m 17s\tremaining: 1m 16s\n",
      "161:\tlearn: 0.2237015\ttotal: 5m 19s\tremaining: 1m 14s\n",
      "162:\tlearn: 0.2231725\ttotal: 5m 21s\tremaining: 1m 12s\n",
      "163:\tlearn: 0.2229052\ttotal: 5m 23s\tremaining: 1m 10s\n",
      "164:\tlearn: 0.2224752\ttotal: 5m 24s\tremaining: 1m 8s\n",
      "165:\tlearn: 0.2221170\ttotal: 5m 26s\tremaining: 1m 6s\n",
      "166:\tlearn: 0.2217458\ttotal: 5m 28s\tremaining: 1m 4s\n",
      "167:\tlearn: 0.2214862\ttotal: 5m 30s\tremaining: 1m 2s\n",
      "168:\tlearn: 0.2210353\ttotal: 5m 32s\tremaining: 1m\n",
      "169:\tlearn: 0.2204816\ttotal: 5m 34s\tremaining: 59s\n",
      "170:\tlearn: 0.2201107\ttotal: 5m 36s\tremaining: 57.1s\n",
      "171:\tlearn: 0.2196634\ttotal: 5m 38s\tremaining: 55.1s\n",
      "172:\tlearn: 0.2187343\ttotal: 5m 40s\tremaining: 53.1s\n",
      "173:\tlearn: 0.2184598\ttotal: 5m 42s\tremaining: 51.1s\n",
      "174:\tlearn: 0.2181016\ttotal: 5m 44s\tremaining: 49.2s\n",
      "175:\tlearn: 0.2178534\ttotal: 5m 46s\tremaining: 47.2s\n",
      "176:\tlearn: 0.2173855\ttotal: 5m 48s\tremaining: 45.2s\n",
      "177:\tlearn: 0.2169177\ttotal: 5m 50s\tremaining: 43.3s\n",
      "178:\tlearn: 0.2163551\ttotal: 5m 52s\tremaining: 41.3s\n",
      "179:\tlearn: 0.2157380\ttotal: 5m 54s\tremaining: 39.4s\n",
      "180:\tlearn: 0.2151743\ttotal: 5m 56s\tremaining: 37.4s\n",
      "181:\tlearn: 0.2149410\ttotal: 5m 58s\tremaining: 35.4s\n",
      "182:\tlearn: 0.2143615\ttotal: 6m\tremaining: 33.4s\n",
      "183:\tlearn: 0.2140468\ttotal: 6m 1s\tremaining: 31.5s\n",
      "184:\tlearn: 0.2135460\ttotal: 6m 3s\tremaining: 29.5s\n",
      "185:\tlearn: 0.2132164\ttotal: 6m 5s\tremaining: 27.5s\n",
      "186:\tlearn: 0.2129755\ttotal: 6m 7s\tremaining: 25.6s\n",
      "187:\tlearn: 0.2125640\ttotal: 6m 9s\tremaining: 23.6s\n",
      "188:\tlearn: 0.2118599\ttotal: 6m 11s\tremaining: 21.6s\n",
      "189:\tlearn: 0.2115069\ttotal: 6m 13s\tremaining: 19.7s\n",
      "190:\tlearn: 0.2108996\ttotal: 6m 15s\tremaining: 17.7s\n",
      "191:\tlearn: 0.2103060\ttotal: 6m 17s\tremaining: 15.7s\n",
      "192:\tlearn: 0.2098885\ttotal: 6m 19s\tremaining: 13.8s\n",
      "193:\tlearn: 0.2096316\ttotal: 6m 21s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2094074\ttotal: 6m 23s\tremaining: 9.82s\n",
      "195:\tlearn: 0.2091817\ttotal: 6m 24s\tremaining: 7.85s\n",
      "196:\tlearn: 0.2086779\ttotal: 6m 26s\tremaining: 5.89s\n",
      "197:\tlearn: 0.2083153\ttotal: 6m 28s\tremaining: 3.92s\n",
      "198:\tlearn: 0.2081039\ttotal: 6m 30s\tremaining: 1.96s\n",
      "199:\tlearn: 0.2074890\ttotal: 6m 32s\tremaining: 0us\n",
      "Learning rate set to 0.287155\n",
      "0:\tlearn: 0.5838601\ttotal: 2.01s\tremaining: 6m 39s\n",
      "1:\tlearn: 0.5460155\ttotal: 4.15s\tremaining: 6m 50s\n",
      "2:\tlearn: 0.5208511\ttotal: 6.18s\tremaining: 6m 45s\n",
      "3:\tlearn: 0.5076151\ttotal: 8.16s\tremaining: 6m 39s\n",
      "4:\tlearn: 0.4938599\ttotal: 10.2s\tremaining: 6m 36s\n",
      "5:\tlearn: 0.4820529\ttotal: 12.2s\tremaining: 6m 32s\n",
      "6:\tlearn: 0.4729227\ttotal: 14.2s\tremaining: 6m 31s\n",
      "7:\tlearn: 0.4596836\ttotal: 16.2s\tremaining: 6m 28s\n",
      "8:\tlearn: 0.4518001\ttotal: 18.1s\tremaining: 6m 24s\n",
      "9:\tlearn: 0.4450726\ttotal: 20.1s\tremaining: 6m 21s\n",
      "10:\tlearn: 0.4391613\ttotal: 22.1s\tremaining: 6m 19s\n",
      "11:\tlearn: 0.4287726\ttotal: 24.2s\tremaining: 6m 19s\n",
      "12:\tlearn: 0.4243115\ttotal: 26.2s\tremaining: 6m 16s\n",
      "13:\tlearn: 0.4189191\ttotal: 28.2s\tremaining: 6m 14s\n",
      "14:\tlearn: 0.4145128\ttotal: 30.2s\tremaining: 6m 12s\n",
      "15:\tlearn: 0.4115706\ttotal: 32.2s\tremaining: 6m 10s\n",
      "16:\tlearn: 0.4080393\ttotal: 34.3s\tremaining: 6m 9s\n",
      "17:\tlearn: 0.4036096\ttotal: 36.3s\tremaining: 6m 6s\n",
      "18:\tlearn: 0.4003694\ttotal: 38.2s\tremaining: 6m 4s\n",
      "19:\tlearn: 0.3970708\ttotal: 40.2s\tremaining: 6m 1s\n",
      "20:\tlearn: 0.3942914\ttotal: 42.2s\tremaining: 5m 59s\n",
      "21:\tlearn: 0.3894250\ttotal: 44.3s\tremaining: 5m 58s\n",
      "22:\tlearn: 0.3866091\ttotal: 46.2s\tremaining: 5m 55s\n",
      "23:\tlearn: 0.3818701\ttotal: 48.3s\tremaining: 5m 53s\n",
      "24:\tlearn: 0.3790619\ttotal: 50.3s\tremaining: 5m 52s\n",
      "25:\tlearn: 0.3768816\ttotal: 52.4s\tremaining: 5m 50s\n",
      "26:\tlearn: 0.3744896\ttotal: 54.5s\tremaining: 5m 49s\n",
      "27:\tlearn: 0.3721126\ttotal: 56.5s\tremaining: 5m 47s\n",
      "28:\tlearn: 0.3687512\ttotal: 58.6s\tremaining: 5m 45s\n",
      "29:\tlearn: 0.3669409\ttotal: 1m\tremaining: 5m 43s\n",
      "30:\tlearn: 0.3644021\ttotal: 1m 2s\tremaining: 5m 41s\n",
      "31:\tlearn: 0.3618321\ttotal: 1m 4s\tremaining: 5m 39s\n",
      "32:\tlearn: 0.3601602\ttotal: 1m 6s\tremaining: 5m 37s\n",
      "33:\tlearn: 0.3582085\ttotal: 1m 8s\tremaining: 5m 35s\n",
      "34:\tlearn: 0.3560453\ttotal: 1m 10s\tremaining: 5m 33s\n",
      "35:\tlearn: 0.3533339\ttotal: 1m 12s\tremaining: 5m 30s\n",
      "36:\tlearn: 0.3504473\ttotal: 1m 14s\tremaining: 5m 28s\n",
      "37:\tlearn: 0.3484481\ttotal: 1m 16s\tremaining: 5m 26s\n",
      "38:\tlearn: 0.3466501\ttotal: 1m 18s\tremaining: 5m 24s\n",
      "39:\tlearn: 0.3444687\ttotal: 1m 20s\tremaining: 5m 22s\n",
      "40:\tlearn: 0.3412932\ttotal: 1m 22s\tremaining: 5m 20s\n",
      "41:\tlearn: 0.3394972\ttotal: 1m 24s\tremaining: 5m 18s\n",
      "42:\tlearn: 0.3379971\ttotal: 1m 26s\tremaining: 5m 15s\n",
      "43:\tlearn: 0.3363103\ttotal: 1m 28s\tremaining: 5m 13s\n",
      "44:\tlearn: 0.3339811\ttotal: 1m 30s\tremaining: 5m 11s\n",
      "45:\tlearn: 0.3316533\ttotal: 1m 32s\tremaining: 5m 9s\n",
      "46:\tlearn: 0.3297450\ttotal: 1m 34s\tremaining: 5m 7s\n",
      "47:\tlearn: 0.3272493\ttotal: 1m 36s\tremaining: 5m 5s\n",
      "48:\tlearn: 0.3256106\ttotal: 1m 38s\tremaining: 5m 3s\n",
      "49:\tlearn: 0.3241776\ttotal: 1m 40s\tremaining: 5m 1s\n",
      "50:\tlearn: 0.3225476\ttotal: 1m 42s\tremaining: 4m 59s\n",
      "51:\tlearn: 0.3211612\ttotal: 1m 44s\tremaining: 4m 57s\n",
      "52:\tlearn: 0.3197379\ttotal: 1m 46s\tremaining: 4m 54s\n",
      "53:\tlearn: 0.3183156\ttotal: 1m 48s\tremaining: 4m 53s\n",
      "54:\tlearn: 0.3167701\ttotal: 1m 50s\tremaining: 4m 51s\n",
      "55:\tlearn: 0.3152874\ttotal: 1m 52s\tremaining: 4m 49s\n",
      "56:\tlearn: 0.3138553\ttotal: 1m 54s\tremaining: 4m 47s\n",
      "57:\tlearn: 0.3124130\ttotal: 1m 56s\tremaining: 4m 45s\n",
      "58:\tlearn: 0.3112077\ttotal: 1m 58s\tremaining: 4m 43s\n",
      "59:\tlearn: 0.3097814\ttotal: 2m\tremaining: 4m 41s\n",
      "60:\tlearn: 0.3086855\ttotal: 2m 2s\tremaining: 4m 39s\n",
      "61:\tlearn: 0.3069920\ttotal: 2m 4s\tremaining: 4m 37s\n",
      "62:\tlearn: 0.3050972\ttotal: 2m 6s\tremaining: 4m 35s\n",
      "63:\tlearn: 0.3034977\ttotal: 2m 8s\tremaining: 4m 33s\n",
      "64:\tlearn: 0.3020976\ttotal: 2m 10s\tremaining: 4m 31s\n",
      "65:\tlearn: 0.3005482\ttotal: 2m 12s\tremaining: 4m 29s\n",
      "66:\tlearn: 0.2993135\ttotal: 2m 14s\tremaining: 4m 27s\n",
      "67:\tlearn: 0.2979578\ttotal: 2m 16s\tremaining: 4m 25s\n",
      "68:\tlearn: 0.2966825\ttotal: 2m 18s\tremaining: 4m 23s\n",
      "69:\tlearn: 0.2956254\ttotal: 2m 20s\tremaining: 4m 21s\n",
      "70:\tlearn: 0.2944642\ttotal: 2m 22s\tremaining: 4m 18s\n",
      "71:\tlearn: 0.2932741\ttotal: 2m 24s\tremaining: 4m 16s\n",
      "72:\tlearn: 0.2919105\ttotal: 2m 26s\tremaining: 4m 14s\n",
      "73:\tlearn: 0.2908114\ttotal: 2m 28s\tremaining: 4m 12s\n",
      "74:\tlearn: 0.2895909\ttotal: 2m 30s\tremaining: 4m 10s\n",
      "75:\tlearn: 0.2885058\ttotal: 2m 32s\tremaining: 4m 8s\n",
      "76:\tlearn: 0.2872187\ttotal: 2m 34s\tremaining: 4m 6s\n",
      "77:\tlearn: 0.2859396\ttotal: 2m 36s\tremaining: 4m 4s\n",
      "78:\tlearn: 0.2848506\ttotal: 2m 38s\tremaining: 4m 2s\n",
      "79:\tlearn: 0.2840152\ttotal: 2m 40s\tremaining: 4m\n",
      "80:\tlearn: 0.2829733\ttotal: 2m 42s\tremaining: 3m 58s\n",
      "81:\tlearn: 0.2818429\ttotal: 2m 44s\tremaining: 3m 56s\n",
      "82:\tlearn: 0.2808001\ttotal: 2m 46s\tremaining: 3m 54s\n",
      "83:\tlearn: 0.2800760\ttotal: 2m 47s\tremaining: 3m 51s\n",
      "84:\tlearn: 0.2785839\ttotal: 2m 49s\tremaining: 3m 49s\n",
      "85:\tlearn: 0.2777131\ttotal: 2m 51s\tremaining: 3m 47s\n",
      "86:\tlearn: 0.2771216\ttotal: 2m 53s\tremaining: 3m 45s\n",
      "87:\tlearn: 0.2764801\ttotal: 2m 55s\tremaining: 3m 43s\n",
      "88:\tlearn: 0.2757700\ttotal: 2m 57s\tremaining: 3m 41s\n",
      "89:\tlearn: 0.2750081\ttotal: 2m 59s\tremaining: 3m 39s\n",
      "90:\tlearn: 0.2738530\ttotal: 3m 1s\tremaining: 3m 37s\n",
      "91:\tlearn: 0.2730428\ttotal: 3m 3s\tremaining: 3m 35s\n",
      "92:\tlearn: 0.2724721\ttotal: 3m 5s\tremaining: 3m 33s\n",
      "93:\tlearn: 0.2715617\ttotal: 3m 7s\tremaining: 3m 31s\n",
      "94:\tlearn: 0.2706878\ttotal: 3m 9s\tremaining: 3m 29s\n",
      "95:\tlearn: 0.2698187\ttotal: 3m 11s\tremaining: 3m 27s\n",
      "96:\tlearn: 0.2688752\ttotal: 3m 13s\tremaining: 3m 25s\n",
      "97:\tlearn: 0.2680320\ttotal: 3m 15s\tremaining: 3m 23s\n",
      "98:\tlearn: 0.2673722\ttotal: 3m 17s\tremaining: 3m 21s\n",
      "99:\tlearn: 0.2662127\ttotal: 3m 19s\tremaining: 3m 19s\n",
      "100:\tlearn: 0.2652803\ttotal: 3m 21s\tremaining: 3m 17s\n",
      "101:\tlearn: 0.2643615\ttotal: 3m 23s\tremaining: 3m 15s\n",
      "102:\tlearn: 0.2636226\ttotal: 3m 25s\tremaining: 3m 13s\n",
      "103:\tlearn: 0.2627663\ttotal: 3m 27s\tremaining: 3m 11s\n",
      "104:\tlearn: 0.2621887\ttotal: 3m 29s\tremaining: 3m 9s\n",
      "105:\tlearn: 0.2614649\ttotal: 3m 31s\tremaining: 3m 7s\n",
      "106:\tlearn: 0.2610172\ttotal: 3m 33s\tremaining: 3m 5s\n",
      "107:\tlearn: 0.2602855\ttotal: 3m 35s\tremaining: 3m 3s\n",
      "108:\tlearn: 0.2594408\ttotal: 3m 37s\tremaining: 3m 1s\n",
      "109:\tlearn: 0.2586486\ttotal: 3m 39s\tremaining: 2m 59s\n",
      "110:\tlearn: 0.2580137\ttotal: 3m 41s\tremaining: 2m 57s\n",
      "111:\tlearn: 0.2572214\ttotal: 3m 43s\tremaining: 2m 55s\n",
      "112:\tlearn: 0.2559409\ttotal: 3m 45s\tremaining: 2m 53s\n",
      "113:\tlearn: 0.2553171\ttotal: 3m 47s\tremaining: 2m 51s\n",
      "114:\tlearn: 0.2548286\ttotal: 3m 49s\tremaining: 2m 49s\n",
      "115:\tlearn: 0.2542646\ttotal: 3m 50s\tremaining: 2m 47s\n",
      "116:\tlearn: 0.2538195\ttotal: 3m 52s\tremaining: 2m 45s\n",
      "117:\tlearn: 0.2533539\ttotal: 3m 54s\tremaining: 2m 43s\n",
      "118:\tlearn: 0.2528671\ttotal: 3m 56s\tremaining: 2m 41s\n",
      "119:\tlearn: 0.2516969\ttotal: 3m 58s\tremaining: 2m 39s\n",
      "120:\tlearn: 0.2508013\ttotal: 4m\tremaining: 2m 37s\n",
      "121:\tlearn: 0.2502212\ttotal: 4m 2s\tremaining: 2m 35s\n",
      "122:\tlearn: 0.2496887\ttotal: 4m 4s\tremaining: 2m 33s\n",
      "123:\tlearn: 0.2487443\ttotal: 4m 7s\tremaining: 2m 31s\n",
      "124:\tlearn: 0.2483421\ttotal: 4m 9s\tremaining: 2m 29s\n",
      "125:\tlearn: 0.2475703\ttotal: 4m 11s\tremaining: 2m 27s\n",
      "126:\tlearn: 0.2469325\ttotal: 4m 13s\tremaining: 2m 25s\n",
      "127:\tlearn: 0.2463279\ttotal: 4m 15s\tremaining: 2m 23s\n",
      "128:\tlearn: 0.2456180\ttotal: 4m 16s\tremaining: 2m 21s\n",
      "129:\tlearn: 0.2451609\ttotal: 4m 18s\tremaining: 2m 19s\n",
      "130:\tlearn: 0.2443999\ttotal: 4m 20s\tremaining: 2m 17s\n",
      "131:\tlearn: 0.2440485\ttotal: 4m 22s\tremaining: 2m 15s\n",
      "132:\tlearn: 0.2432775\ttotal: 4m 24s\tremaining: 2m 13s\n",
      "133:\tlearn: 0.2427545\ttotal: 4m 26s\tremaining: 2m 11s\n",
      "134:\tlearn: 0.2422678\ttotal: 4m 28s\tremaining: 2m 9s\n",
      "135:\tlearn: 0.2415574\ttotal: 4m 30s\tremaining: 2m 7s\n",
      "136:\tlearn: 0.2411909\ttotal: 4m 32s\tremaining: 2m 5s\n",
      "137:\tlearn: 0.2407865\ttotal: 4m 34s\tremaining: 2m 3s\n",
      "138:\tlearn: 0.2398892\ttotal: 4m 36s\tremaining: 2m 1s\n",
      "139:\tlearn: 0.2393976\ttotal: 4m 38s\tremaining: 1m 59s\n",
      "140:\tlearn: 0.2388797\ttotal: 4m 40s\tremaining: 1m 57s\n",
      "141:\tlearn: 0.2385108\ttotal: 4m 41s\tremaining: 1m 55s\n",
      "142:\tlearn: 0.2381865\ttotal: 4m 43s\tremaining: 1m 53s\n",
      "143:\tlearn: 0.2378792\ttotal: 4m 45s\tremaining: 1m 51s\n",
      "144:\tlearn: 0.2374452\ttotal: 4m 47s\tremaining: 1m 49s\n",
      "145:\tlearn: 0.2365211\ttotal: 4m 49s\tremaining: 1m 47s\n",
      "146:\tlearn: 0.2360346\ttotal: 4m 51s\tremaining: 1m 45s\n",
      "147:\tlearn: 0.2353803\ttotal: 4m 53s\tremaining: 1m 43s\n",
      "148:\tlearn: 0.2347612\ttotal: 4m 55s\tremaining: 1m 41s\n",
      "149:\tlearn: 0.2333123\ttotal: 4m 57s\tremaining: 1m 39s\n",
      "150:\tlearn: 0.2328413\ttotal: 4m 59s\tremaining: 1m 37s\n",
      "151:\tlearn: 0.2323710\ttotal: 5m 1s\tremaining: 1m 35s\n",
      "152:\tlearn: 0.2317807\ttotal: 5m 3s\tremaining: 1m 33s\n",
      "153:\tlearn: 0.2311617\ttotal: 5m 5s\tremaining: 1m 31s\n",
      "154:\tlearn: 0.2308412\ttotal: 5m 7s\tremaining: 1m 29s\n",
      "155:\tlearn: 0.2303160\ttotal: 5m 9s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.2297222\ttotal: 5m 11s\tremaining: 1m 25s\n",
      "157:\tlearn: 0.2293660\ttotal: 5m 13s\tremaining: 1m 23s\n",
      "158:\tlearn: 0.2290687\ttotal: 5m 15s\tremaining: 1m 21s\n",
      "159:\tlearn: 0.2283571\ttotal: 5m 17s\tremaining: 1m 19s\n",
      "160:\tlearn: 0.2274537\ttotal: 5m 18s\tremaining: 1m 17s\n",
      "161:\tlearn: 0.2271650\ttotal: 5m 20s\tremaining: 1m 15s\n",
      "162:\tlearn: 0.2267077\ttotal: 5m 22s\tremaining: 1m 13s\n",
      "163:\tlearn: 0.2263807\ttotal: 5m 24s\tremaining: 1m 11s\n",
      "164:\tlearn: 0.2258180\ttotal: 5m 26s\tremaining: 1m 9s\n",
      "165:\tlearn: 0.2253913\ttotal: 5m 28s\tremaining: 1m 7s\n",
      "166:\tlearn: 0.2249057\ttotal: 5m 30s\tremaining: 1m 5s\n",
      "167:\tlearn: 0.2239899\ttotal: 5m 32s\tremaining: 1m 3s\n",
      "168:\tlearn: 0.2231378\ttotal: 5m 34s\tremaining: 1m 1s\n",
      "169:\tlearn: 0.2228039\ttotal: 5m 36s\tremaining: 59.4s\n",
      "170:\tlearn: 0.2221304\ttotal: 5m 38s\tremaining: 57.5s\n",
      "171:\tlearn: 0.2218587\ttotal: 5m 40s\tremaining: 55.5s\n",
      "172:\tlearn: 0.2213862\ttotal: 5m 42s\tremaining: 53.5s\n",
      "173:\tlearn: 0.2210086\ttotal: 5m 44s\tremaining: 51.5s\n",
      "174:\tlearn: 0.2207237\ttotal: 5m 46s\tremaining: 49.5s\n",
      "175:\tlearn: 0.2203206\ttotal: 5m 48s\tremaining: 47.5s\n",
      "176:\tlearn: 0.2198520\ttotal: 5m 50s\tremaining: 45.5s\n",
      "177:\tlearn: 0.2195996\ttotal: 5m 52s\tremaining: 43.5s\n",
      "178:\tlearn: 0.2188973\ttotal: 5m 54s\tremaining: 41.6s\n",
      "179:\tlearn: 0.2183845\ttotal: 5m 56s\tremaining: 39.6s\n",
      "180:\tlearn: 0.2180152\ttotal: 5m 58s\tremaining: 37.6s\n",
      "181:\tlearn: 0.2176438\ttotal: 6m\tremaining: 35.6s\n",
      "182:\tlearn: 0.2170645\ttotal: 6m 2s\tremaining: 33.7s\n",
      "183:\tlearn: 0.2165762\ttotal: 6m 4s\tremaining: 31.7s\n",
      "184:\tlearn: 0.2161056\ttotal: 6m 6s\tremaining: 29.7s\n",
      "185:\tlearn: 0.2158544\ttotal: 6m 8s\tremaining: 27.7s\n",
      "186:\tlearn: 0.2154267\ttotal: 6m 10s\tremaining: 25.7s\n",
      "187:\tlearn: 0.2150059\ttotal: 6m 11s\tremaining: 23.7s\n",
      "188:\tlearn: 0.2145784\ttotal: 6m 13s\tremaining: 21.8s\n",
      "189:\tlearn: 0.2140460\ttotal: 6m 15s\tremaining: 19.8s\n",
      "190:\tlearn: 0.2138028\ttotal: 6m 17s\tremaining: 17.8s\n",
      "191:\tlearn: 0.2131106\ttotal: 6m 19s\tremaining: 15.8s\n",
      "192:\tlearn: 0.2125551\ttotal: 6m 21s\tremaining: 13.8s\n",
      "193:\tlearn: 0.2122412\ttotal: 6m 23s\tremaining: 11.9s\n",
      "194:\tlearn: 0.2119217\ttotal: 6m 25s\tremaining: 9.88s\n",
      "195:\tlearn: 0.2114806\ttotal: 6m 27s\tremaining: 7.91s\n",
      "196:\tlearn: 0.2112290\ttotal: 6m 29s\tremaining: 5.93s\n",
      "197:\tlearn: 0.2109922\ttotal: 6m 31s\tremaining: 3.95s\n",
      "198:\tlearn: 0.2106773\ttotal: 6m 32s\tremaining: 1.97s\n",
      "199:\tlearn: 0.2102238\ttotal: 6m 34s\tremaining: 0us\n",
      "Learning rate set to 0.287155\n",
      "0:\tlearn: 0.5823079\ttotal: 2.08s\tremaining: 6m 54s\n",
      "1:\tlearn: 0.5455124\ttotal: 4.19s\tremaining: 6m 55s\n",
      "2:\tlearn: 0.5280939\ttotal: 6.3s\tremaining: 6m 53s\n",
      "3:\tlearn: 0.5051032\ttotal: 8.39s\tremaining: 6m 51s\n",
      "4:\tlearn: 0.4890761\ttotal: 10.5s\tremaining: 6m 48s\n",
      "5:\tlearn: 0.4783934\ttotal: 12.6s\tremaining: 6m 48s\n",
      "6:\tlearn: 0.4662504\ttotal: 14.7s\tremaining: 6m 44s\n",
      "7:\tlearn: 0.4545233\ttotal: 16.6s\tremaining: 6m 39s\n",
      "8:\tlearn: 0.4475930\ttotal: 18.6s\tremaining: 6m 35s\n",
      "9:\tlearn: 0.4381756\ttotal: 20.6s\tremaining: 6m 31s\n",
      "10:\tlearn: 0.4321668\ttotal: 22.7s\tremaining: 6m 29s\n",
      "11:\tlearn: 0.4249328\ttotal: 24.7s\tremaining: 6m 27s\n",
      "12:\tlearn: 0.4199922\ttotal: 26.7s\tremaining: 6m 24s\n",
      "13:\tlearn: 0.4153900\ttotal: 28.7s\tremaining: 6m 21s\n",
      "14:\tlearn: 0.4091112\ttotal: 30.7s\tremaining: 6m 18s\n",
      "15:\tlearn: 0.4048690\ttotal: 32.7s\tremaining: 6m 16s\n",
      "16:\tlearn: 0.3996556\ttotal: 34.7s\tremaining: 6m 13s\n",
      "17:\tlearn: 0.3958243\ttotal: 36.7s\tremaining: 6m 11s\n",
      "18:\tlearn: 0.3930329\ttotal: 38.7s\tremaining: 6m 8s\n",
      "19:\tlearn: 0.3898202\ttotal: 40.8s\tremaining: 6m 6s\n",
      "20:\tlearn: 0.3875593\ttotal: 42.9s\tremaining: 6m 5s\n",
      "21:\tlearn: 0.3854716\ttotal: 45s\tremaining: 6m 3s\n",
      "22:\tlearn: 0.3830878\ttotal: 47s\tremaining: 6m 1s\n",
      "23:\tlearn: 0.3808910\ttotal: 49s\tremaining: 5m 59s\n",
      "24:\tlearn: 0.3782498\ttotal: 51s\tremaining: 5m 56s\n",
      "25:\tlearn: 0.3751604\ttotal: 53s\tremaining: 5m 54s\n",
      "26:\tlearn: 0.3729382\ttotal: 55.1s\tremaining: 5m 52s\n",
      "27:\tlearn: 0.3706075\ttotal: 57.2s\tremaining: 5m 51s\n",
      "28:\tlearn: 0.3683149\ttotal: 59.3s\tremaining: 5m 49s\n",
      "29:\tlearn: 0.3661931\ttotal: 1m 1s\tremaining: 5m 47s\n",
      "30:\tlearn: 0.3642751\ttotal: 1m 3s\tremaining: 5m 46s\n",
      "31:\tlearn: 0.3620684\ttotal: 1m 5s\tremaining: 5m 43s\n",
      "32:\tlearn: 0.3599320\ttotal: 1m 7s\tremaining: 5m 42s\n",
      "33:\tlearn: 0.3565966\ttotal: 1m 9s\tremaining: 5m 39s\n",
      "34:\tlearn: 0.3544711\ttotal: 1m 11s\tremaining: 5m 37s\n",
      "35:\tlearn: 0.3524035\ttotal: 1m 13s\tremaining: 5m 36s\n",
      "36:\tlearn: 0.3484455\ttotal: 1m 15s\tremaining: 5m 34s\n",
      "37:\tlearn: 0.3469339\ttotal: 1m 17s\tremaining: 5m 32s\n",
      "38:\tlearn: 0.3450048\ttotal: 1m 19s\tremaining: 5m 30s\n",
      "39:\tlearn: 0.3423330\ttotal: 1m 21s\tremaining: 5m 27s\n",
      "40:\tlearn: 0.3404094\ttotal: 1m 24s\tremaining: 5m 25s\n",
      "41:\tlearn: 0.3388252\ttotal: 1m 26s\tremaining: 5m 23s\n",
      "42:\tlearn: 0.3364322\ttotal: 1m 28s\tremaining: 5m 21s\n",
      "43:\tlearn: 0.3341979\ttotal: 1m 30s\tremaining: 5m 19s\n",
      "44:\tlearn: 0.3316276\ttotal: 1m 32s\tremaining: 5m 16s\n",
      "45:\tlearn: 0.3299322\ttotal: 1m 34s\tremaining: 5m 14s\n",
      "46:\tlearn: 0.3280279\ttotal: 1m 35s\tremaining: 5m 12s\n",
      "47:\tlearn: 0.3262723\ttotal: 1m 37s\tremaining: 5m 10s\n",
      "48:\tlearn: 0.3243423\ttotal: 1m 39s\tremaining: 5m 7s\n",
      "49:\tlearn: 0.3229696\ttotal: 1m 41s\tremaining: 5m 5s\n",
      "50:\tlearn: 0.3204324\ttotal: 1m 43s\tremaining: 5m 3s\n",
      "51:\tlearn: 0.3189187\ttotal: 1m 45s\tremaining: 5m 1s\n",
      "52:\tlearn: 0.3174866\ttotal: 1m 47s\tremaining: 4m 58s\n",
      "53:\tlearn: 0.3152945\ttotal: 1m 49s\tremaining: 4m 56s\n",
      "54:\tlearn: 0.3136876\ttotal: 1m 51s\tremaining: 4m 54s\n",
      "55:\tlearn: 0.3122342\ttotal: 1m 53s\tremaining: 4m 52s\n",
      "56:\tlearn: 0.3107717\ttotal: 1m 55s\tremaining: 4m 49s\n",
      "57:\tlearn: 0.3094819\ttotal: 1m 57s\tremaining: 4m 47s\n",
      "58:\tlearn: 0.3080848\ttotal: 1m 59s\tremaining: 4m 45s\n",
      "59:\tlearn: 0.3068863\ttotal: 2m 1s\tremaining: 4m 43s\n",
      "60:\tlearn: 0.3055267\ttotal: 2m 3s\tremaining: 4m 41s\n",
      "61:\tlearn: 0.3042794\ttotal: 2m 5s\tremaining: 4m 39s\n",
      "62:\tlearn: 0.3030572\ttotal: 2m 7s\tremaining: 4m 37s\n",
      "63:\tlearn: 0.3021424\ttotal: 2m 9s\tremaining: 4m 34s\n",
      "64:\tlearn: 0.3007969\ttotal: 2m 11s\tremaining: 4m 32s\n",
      "65:\tlearn: 0.2992883\ttotal: 2m 13s\tremaining: 4m 30s\n",
      "66:\tlearn: 0.2981171\ttotal: 2m 15s\tremaining: 4m 28s\n",
      "67:\tlearn: 0.2967900\ttotal: 2m 17s\tremaining: 4m 26s\n",
      "68:\tlearn: 0.2954778\ttotal: 2m 19s\tremaining: 4m 24s\n",
      "69:\tlearn: 0.2941910\ttotal: 2m 21s\tremaining: 4m 22s\n",
      "70:\tlearn: 0.2929218\ttotal: 2m 23s\tremaining: 4m 20s\n",
      "71:\tlearn: 0.2917606\ttotal: 2m 25s\tremaining: 4m 18s\n",
      "72:\tlearn: 0.2903400\ttotal: 2m 27s\tremaining: 4m 16s\n",
      "73:\tlearn: 0.2894106\ttotal: 2m 29s\tremaining: 4m 14s\n",
      "74:\tlearn: 0.2879843\ttotal: 2m 31s\tremaining: 4m 11s\n",
      "75:\tlearn: 0.2870924\ttotal: 2m 33s\tremaining: 4m 9s\n",
      "76:\tlearn: 0.2859754\ttotal: 2m 34s\tremaining: 4m 7s\n",
      "77:\tlearn: 0.2848473\ttotal: 2m 36s\tremaining: 4m 5s\n",
      "78:\tlearn: 0.2834288\ttotal: 2m 38s\tremaining: 4m 3s\n",
      "79:\tlearn: 0.2825336\ttotal: 2m 40s\tremaining: 4m 1s\n",
      "80:\tlearn: 0.2815357\ttotal: 2m 42s\tremaining: 3m 58s\n",
      "81:\tlearn: 0.2803178\ttotal: 2m 44s\tremaining: 3m 56s\n",
      "82:\tlearn: 0.2794808\ttotal: 2m 46s\tremaining: 3m 54s\n",
      "83:\tlearn: 0.2777513\ttotal: 2m 48s\tremaining: 3m 52s\n",
      "84:\tlearn: 0.2768162\ttotal: 2m 50s\tremaining: 3m 50s\n",
      "85:\tlearn: 0.2759987\ttotal: 2m 52s\tremaining: 3m 48s\n",
      "86:\tlearn: 0.2746165\ttotal: 2m 54s\tremaining: 3m 46s\n",
      "87:\tlearn: 0.2737033\ttotal: 2m 56s\tremaining: 3m 44s\n",
      "88:\tlearn: 0.2728570\ttotal: 2m 58s\tremaining: 3m 42s\n",
      "89:\tlearn: 0.2719690\ttotal: 3m\tremaining: 3m 40s\n",
      "90:\tlearn: 0.2712878\ttotal: 3m 2s\tremaining: 3m 38s\n",
      "91:\tlearn: 0.2704471\ttotal: 3m 4s\tremaining: 3m 36s\n",
      "92:\tlearn: 0.2695846\ttotal: 3m 6s\tremaining: 3m 34s\n",
      "93:\tlearn: 0.2686744\ttotal: 3m 8s\tremaining: 3m 32s\n",
      "94:\tlearn: 0.2678921\ttotal: 3m 10s\tremaining: 3m 30s\n",
      "95:\tlearn: 0.2667392\ttotal: 3m 12s\tremaining: 3m 28s\n",
      "96:\tlearn: 0.2661858\ttotal: 3m 14s\tremaining: 3m 26s\n",
      "97:\tlearn: 0.2653266\ttotal: 3m 16s\tremaining: 3m 24s\n",
      "98:\tlearn: 0.2645395\ttotal: 3m 18s\tremaining: 3m 22s\n",
      "99:\tlearn: 0.2636576\ttotal: 3m 20s\tremaining: 3m 20s\n",
      "100:\tlearn: 0.2630829\ttotal: 3m 22s\tremaining: 3m 18s\n",
      "101:\tlearn: 0.2619350\ttotal: 3m 24s\tremaining: 3m 16s\n",
      "102:\tlearn: 0.2609268\ttotal: 3m 26s\tremaining: 3m 14s\n",
      "103:\tlearn: 0.2602292\ttotal: 3m 28s\tremaining: 3m 12s\n",
      "104:\tlearn: 0.2594291\ttotal: 3m 29s\tremaining: 3m 9s\n",
      "105:\tlearn: 0.2585943\ttotal: 3m 31s\tremaining: 3m 7s\n",
      "106:\tlearn: 0.2577232\ttotal: 3m 33s\tremaining: 3m 5s\n",
      "107:\tlearn: 0.2572502\ttotal: 3m 35s\tremaining: 3m 3s\n",
      "108:\tlearn: 0.2565945\ttotal: 3m 37s\tremaining: 3m 1s\n",
      "109:\tlearn: 0.2558102\ttotal: 3m 39s\tremaining: 2m 59s\n",
      "110:\tlearn: 0.2551809\ttotal: 3m 41s\tremaining: 2m 57s\n",
      "111:\tlearn: 0.2540964\ttotal: 3m 43s\tremaining: 2m 55s\n",
      "112:\tlearn: 0.2535384\ttotal: 3m 45s\tremaining: 2m 53s\n",
      "113:\tlearn: 0.2528007\ttotal: 3m 47s\tremaining: 2m 51s\n",
      "114:\tlearn: 0.2522138\ttotal: 3m 49s\tremaining: 2m 49s\n",
      "115:\tlearn: 0.2507744\ttotal: 3m 51s\tremaining: 2m 47s\n",
      "116:\tlearn: 0.2499856\ttotal: 3m 53s\tremaining: 2m 45s\n",
      "117:\tlearn: 0.2491565\ttotal: 3m 55s\tremaining: 2m 43s\n",
      "118:\tlearn: 0.2482413\ttotal: 3m 57s\tremaining: 2m 41s\n",
      "119:\tlearn: 0.2478113\ttotal: 3m 59s\tremaining: 2m 39s\n",
      "120:\tlearn: 0.2471660\ttotal: 4m 1s\tremaining: 2m 37s\n",
      "121:\tlearn: 0.2467643\ttotal: 4m 3s\tremaining: 2m 35s\n",
      "122:\tlearn: 0.2460824\ttotal: 4m 5s\tremaining: 2m 33s\n",
      "123:\tlearn: 0.2456217\ttotal: 4m 6s\tremaining: 2m 31s\n",
      "124:\tlearn: 0.2449875\ttotal: 4m 8s\tremaining: 2m 29s\n",
      "125:\tlearn: 0.2443364\ttotal: 4m 10s\tremaining: 2m 27s\n",
      "126:\tlearn: 0.2439524\ttotal: 4m 12s\tremaining: 2m 25s\n",
      "127:\tlearn: 0.2432511\ttotal: 4m 14s\tremaining: 2m 23s\n",
      "128:\tlearn: 0.2427817\ttotal: 4m 16s\tremaining: 2m 21s\n",
      "129:\tlearn: 0.2421431\ttotal: 4m 18s\tremaining: 2m 19s\n",
      "130:\tlearn: 0.2414733\ttotal: 4m 20s\tremaining: 2m 17s\n",
      "131:\tlearn: 0.2410984\ttotal: 4m 22s\tremaining: 2m 15s\n",
      "132:\tlearn: 0.2403938\ttotal: 4m 24s\tremaining: 2m 13s\n",
      "133:\tlearn: 0.2400595\ttotal: 4m 26s\tremaining: 2m 11s\n",
      "134:\tlearn: 0.2391725\ttotal: 4m 28s\tremaining: 2m 9s\n",
      "135:\tlearn: 0.2387137\ttotal: 4m 30s\tremaining: 2m 7s\n",
      "136:\tlearn: 0.2380766\ttotal: 4m 32s\tremaining: 2m 5s\n",
      "137:\tlearn: 0.2373776\ttotal: 4m 34s\tremaining: 2m 3s\n",
      "138:\tlearn: 0.2370013\ttotal: 4m 36s\tremaining: 2m 1s\n",
      "139:\tlearn: 0.2363638\ttotal: 4m 38s\tremaining: 1m 59s\n",
      "140:\tlearn: 0.2356609\ttotal: 4m 39s\tremaining: 1m 57s\n",
      "141:\tlearn: 0.2350137\ttotal: 4m 41s\tremaining: 1m 55s\n",
      "142:\tlearn: 0.2346268\ttotal: 4m 43s\tremaining: 1m 53s\n",
      "143:\tlearn: 0.2340335\ttotal: 4m 45s\tremaining: 1m 51s\n",
      "144:\tlearn: 0.2330885\ttotal: 4m 47s\tremaining: 1m 49s\n",
      "145:\tlearn: 0.2325550\ttotal: 4m 49s\tremaining: 1m 47s\n",
      "146:\tlearn: 0.2320066\ttotal: 4m 51s\tremaining: 1m 45s\n",
      "147:\tlearn: 0.2313316\ttotal: 4m 53s\tremaining: 1m 43s\n",
      "148:\tlearn: 0.2307034\ttotal: 4m 55s\tremaining: 1m 41s\n",
      "149:\tlearn: 0.2301562\ttotal: 4m 57s\tremaining: 1m 39s\n",
      "150:\tlearn: 0.2295243\ttotal: 4m 59s\tremaining: 1m 37s\n",
      "151:\tlearn: 0.2292237\ttotal: 5m 1s\tremaining: 1m 35s\n",
      "152:\tlearn: 0.2288984\ttotal: 5m 3s\tremaining: 1m 33s\n",
      "153:\tlearn: 0.2280116\ttotal: 5m 5s\tremaining: 1m 31s\n",
      "154:\tlearn: 0.2273723\ttotal: 5m 7s\tremaining: 1m 29s\n",
      "155:\tlearn: 0.2267415\ttotal: 5m 9s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.2263819\ttotal: 5m 11s\tremaining: 1m 25s\n",
      "157:\tlearn: 0.2257663\ttotal: 5m 13s\tremaining: 1m 23s\n",
      "158:\tlearn: 0.2254812\ttotal: 5m 15s\tremaining: 1m 21s\n",
      "159:\tlearn: 0.2250323\ttotal: 5m 17s\tremaining: 1m 19s\n",
      "160:\tlearn: 0.2246517\ttotal: 5m 19s\tremaining: 1m 17s\n",
      "161:\tlearn: 0.2237909\ttotal: 5m 21s\tremaining: 1m 15s\n",
      "162:\tlearn: 0.2235225\ttotal: 5m 22s\tremaining: 1m 13s\n",
      "163:\tlearn: 0.2231491\ttotal: 5m 24s\tremaining: 1m 11s\n",
      "164:\tlearn: 0.2226944\ttotal: 5m 26s\tremaining: 1m 9s\n",
      "165:\tlearn: 0.2224169\ttotal: 5m 28s\tremaining: 1m 7s\n",
      "166:\tlearn: 0.2217963\ttotal: 5m 30s\tremaining: 1m 5s\n",
      "167:\tlearn: 0.2214326\ttotal: 5m 32s\tremaining: 1m 3s\n",
      "168:\tlearn: 0.2210336\ttotal: 5m 34s\tremaining: 1m 1s\n",
      "169:\tlearn: 0.2205085\ttotal: 5m 36s\tremaining: 59.3s\n",
      "170:\tlearn: 0.2202527\ttotal: 5m 37s\tremaining: 57.3s\n",
      "171:\tlearn: 0.2199989\ttotal: 5m 39s\tremaining: 55.3s\n",
      "172:\tlearn: 0.2194221\ttotal: 5m 41s\tremaining: 53.3s\n",
      "173:\tlearn: 0.2191078\ttotal: 5m 43s\tremaining: 51.4s\n",
      "174:\tlearn: 0.2186008\ttotal: 5m 45s\tremaining: 49.4s\n",
      "175:\tlearn: 0.2180279\ttotal: 5m 47s\tremaining: 47.4s\n",
      "176:\tlearn: 0.2177084\ttotal: 5m 49s\tremaining: 45.4s\n",
      "177:\tlearn: 0.2173244\ttotal: 5m 51s\tremaining: 43.4s\n",
      "178:\tlearn: 0.2170781\ttotal: 5m 53s\tremaining: 41.5s\n",
      "179:\tlearn: 0.2166630\ttotal: 5m 55s\tremaining: 39.5s\n",
      "180:\tlearn: 0.2161494\ttotal: 5m 57s\tremaining: 37.5s\n",
      "181:\tlearn: 0.2158425\ttotal: 5m 59s\tremaining: 35.5s\n",
      "182:\tlearn: 0.2153439\ttotal: 6m 1s\tremaining: 33.6s\n",
      "183:\tlearn: 0.2147217\ttotal: 6m 3s\tremaining: 31.6s\n",
      "184:\tlearn: 0.2142539\ttotal: 6m 5s\tremaining: 29.6s\n",
      "185:\tlearn: 0.2134409\ttotal: 6m 7s\tremaining: 27.7s\n",
      "186:\tlearn: 0.2130973\ttotal: 6m 9s\tremaining: 25.7s\n",
      "187:\tlearn: 0.2123745\ttotal: 6m 11s\tremaining: 23.7s\n",
      "188:\tlearn: 0.2121450\ttotal: 6m 13s\tremaining: 21.7s\n",
      "189:\tlearn: 0.2118973\ttotal: 6m 15s\tremaining: 19.8s\n",
      "190:\tlearn: 0.2115642\ttotal: 6m 17s\tremaining: 17.8s\n",
      "191:\tlearn: 0.2112046\ttotal: 6m 19s\tremaining: 15.8s\n",
      "192:\tlearn: 0.2104993\ttotal: 6m 21s\tremaining: 13.8s\n",
      "193:\tlearn: 0.2102684\ttotal: 6m 23s\tremaining: 11.9s\n",
      "194:\tlearn: 0.2097378\ttotal: 6m 25s\tremaining: 9.88s\n",
      "195:\tlearn: 0.2092566\ttotal: 6m 27s\tremaining: 7.9s\n",
      "196:\tlearn: 0.2090293\ttotal: 6m 29s\tremaining: 5.92s\n",
      "197:\tlearn: 0.2085375\ttotal: 6m 31s\tremaining: 3.95s\n",
      "198:\tlearn: 0.2083347\ttotal: 6m 33s\tremaining: 1.98s\n",
      "199:\tlearn: 0.2078328\ttotal: 6m 35s\tremaining: 0us\n",
      "Learning rate set to 0.287155\n",
      "0:\tlearn: 0.5836611\ttotal: 2.03s\tremaining: 6m 43s\n",
      "1:\tlearn: 0.5440482\ttotal: 4.05s\tremaining: 6m 41s\n",
      "2:\tlearn: 0.5241145\ttotal: 6.17s\tremaining: 6m 45s\n",
      "3:\tlearn: 0.5065439\ttotal: 8.25s\tremaining: 6m 44s\n",
      "4:\tlearn: 0.4893053\ttotal: 10.3s\tremaining: 6m 41s\n",
      "5:\tlearn: 0.4786701\ttotal: 12.4s\tremaining: 6m 42s\n",
      "6:\tlearn: 0.4641439\ttotal: 14.5s\tremaining: 6m 39s\n",
      "7:\tlearn: 0.4583684\ttotal: 16.6s\tremaining: 6m 38s\n",
      "8:\tlearn: 0.4493970\ttotal: 18.6s\tremaining: 6m 34s\n",
      "9:\tlearn: 0.4422112\ttotal: 20.7s\tremaining: 6m 33s\n",
      "10:\tlearn: 0.4349636\ttotal: 22.8s\tremaining: 6m 31s\n",
      "11:\tlearn: 0.4287938\ttotal: 24.8s\tremaining: 6m 28s\n",
      "12:\tlearn: 0.4237471\ttotal: 26.8s\tremaining: 6m 24s\n",
      "13:\tlearn: 0.4157877\ttotal: 28.7s\tremaining: 6m 21s\n",
      "14:\tlearn: 0.4115408\ttotal: 30.7s\tremaining: 6m 19s\n",
      "15:\tlearn: 0.4066340\ttotal: 32.8s\tremaining: 6m 16s\n",
      "16:\tlearn: 0.4024072\ttotal: 34.8s\tremaining: 6m 14s\n",
      "17:\tlearn: 0.3977585\ttotal: 36.7s\tremaining: 6m 11s\n",
      "18:\tlearn: 0.3936884\ttotal: 38.6s\tremaining: 6m 8s\n",
      "19:\tlearn: 0.3904273\ttotal: 40.6s\tremaining: 6m 5s\n",
      "20:\tlearn: 0.3874100\ttotal: 42.7s\tremaining: 6m 3s\n",
      "21:\tlearn: 0.3842086\ttotal: 44.6s\tremaining: 6m\n",
      "22:\tlearn: 0.3813591\ttotal: 46.6s\tremaining: 5m 58s\n",
      "23:\tlearn: 0.3791791\ttotal: 48.6s\tremaining: 5m 56s\n",
      "24:\tlearn: 0.3768521\ttotal: 50.5s\tremaining: 5m 53s\n",
      "25:\tlearn: 0.3738229\ttotal: 52.6s\tremaining: 5m 51s\n",
      "26:\tlearn: 0.3712451\ttotal: 54.6s\tremaining: 5m 49s\n",
      "27:\tlearn: 0.3691027\ttotal: 56.5s\tremaining: 5m 47s\n",
      "28:\tlearn: 0.3669126\ttotal: 58.5s\tremaining: 5m 44s\n",
      "29:\tlearn: 0.3648127\ttotal: 1m\tremaining: 5m 42s\n",
      "30:\tlearn: 0.3621038\ttotal: 1m 2s\tremaining: 5m 39s\n",
      "31:\tlearn: 0.3593001\ttotal: 1m 4s\tremaining: 5m 37s\n",
      "32:\tlearn: 0.3570670\ttotal: 1m 6s\tremaining: 5m 35s\n",
      "33:\tlearn: 0.3551952\ttotal: 1m 8s\tremaining: 5m 33s\n",
      "34:\tlearn: 0.3532871\ttotal: 1m 10s\tremaining: 5m 31s\n",
      "35:\tlearn: 0.3511911\ttotal: 1m 12s\tremaining: 5m 29s\n",
      "36:\tlearn: 0.3489110\ttotal: 1m 14s\tremaining: 5m 27s\n",
      "37:\tlearn: 0.3470404\ttotal: 1m 16s\tremaining: 5m 25s\n",
      "38:\tlearn: 0.3443793\ttotal: 1m 18s\tremaining: 5m 23s\n",
      "39:\tlearn: 0.3426481\ttotal: 1m 20s\tremaining: 5m 21s\n",
      "40:\tlearn: 0.3411510\ttotal: 1m 22s\tremaining: 5m 19s\n",
      "41:\tlearn: 0.3387124\ttotal: 1m 24s\tremaining: 5m 17s\n",
      "42:\tlearn: 0.3363834\ttotal: 1m 26s\tremaining: 5m 15s\n",
      "43:\tlearn: 0.3345980\ttotal: 1m 28s\tremaining: 5m 12s\n",
      "44:\tlearn: 0.3326241\ttotal: 1m 30s\tremaining: 5m 10s\n",
      "45:\tlearn: 0.3304999\ttotal: 1m 32s\tremaining: 5m 8s\n",
      "46:\tlearn: 0.3286248\ttotal: 1m 33s\tremaining: 5m 5s\n",
      "47:\tlearn: 0.3269627\ttotal: 1m 35s\tremaining: 5m 3s\n",
      "48:\tlearn: 0.3248173\ttotal: 1m 37s\tremaining: 5m 1s\n",
      "49:\tlearn: 0.3220647\ttotal: 1m 39s\tremaining: 4m 59s\n",
      "50:\tlearn: 0.3206963\ttotal: 1m 41s\tremaining: 4m 57s\n",
      "51:\tlearn: 0.3190246\ttotal: 1m 43s\tremaining: 4m 54s\n",
      "52:\tlearn: 0.3175861\ttotal: 1m 45s\tremaining: 4m 52s\n",
      "53:\tlearn: 0.3155428\ttotal: 1m 47s\tremaining: 4m 50s\n",
      "54:\tlearn: 0.3133032\ttotal: 1m 49s\tremaining: 4m 48s\n",
      "55:\tlearn: 0.3115903\ttotal: 1m 51s\tremaining: 4m 46s\n",
      "56:\tlearn: 0.3098638\ttotal: 1m 53s\tremaining: 4m 44s\n",
      "57:\tlearn: 0.3086831\ttotal: 1m 55s\tremaining: 4m 42s\n",
      "58:\tlearn: 0.3070630\ttotal: 1m 57s\tremaining: 4m 40s\n",
      "59:\tlearn: 0.3054838\ttotal: 1m 59s\tremaining: 4m 38s\n",
      "60:\tlearn: 0.3043371\ttotal: 2m 1s\tremaining: 4m 36s\n",
      "61:\tlearn: 0.3030825\ttotal: 2m 3s\tremaining: 4m 34s\n",
      "62:\tlearn: 0.3018193\ttotal: 2m 5s\tremaining: 4m 32s\n",
      "63:\tlearn: 0.3004710\ttotal: 2m 7s\tremaining: 4m 30s\n",
      "64:\tlearn: 0.2993774\ttotal: 2m 9s\tremaining: 4m 28s\n",
      "65:\tlearn: 0.2975576\ttotal: 2m 11s\tremaining: 4m 26s\n",
      "66:\tlearn: 0.2962626\ttotal: 2m 13s\tremaining: 4m 24s\n",
      "67:\tlearn: 0.2944071\ttotal: 2m 15s\tremaining: 4m 22s\n",
      "68:\tlearn: 0.2933609\ttotal: 2m 17s\tremaining: 4m 20s\n",
      "69:\tlearn: 0.2921517\ttotal: 2m 19s\tremaining: 4m 18s\n",
      "70:\tlearn: 0.2908691\ttotal: 2m 21s\tremaining: 4m 16s\n",
      "71:\tlearn: 0.2898088\ttotal: 2m 23s\tremaining: 4m 14s\n",
      "72:\tlearn: 0.2887449\ttotal: 2m 25s\tremaining: 4m 12s\n",
      "73:\tlearn: 0.2875745\ttotal: 2m 26s\tremaining: 4m 10s\n",
      "74:\tlearn: 0.2864630\ttotal: 2m 28s\tremaining: 4m 8s\n",
      "75:\tlearn: 0.2853261\ttotal: 2m 30s\tremaining: 4m 5s\n",
      "76:\tlearn: 0.2841700\ttotal: 2m 32s\tremaining: 4m 3s\n",
      "77:\tlearn: 0.2830956\ttotal: 2m 34s\tremaining: 4m 1s\n",
      "78:\tlearn: 0.2820940\ttotal: 2m 36s\tremaining: 3m 59s\n",
      "79:\tlearn: 0.2812460\ttotal: 2m 38s\tremaining: 3m 57s\n",
      "80:\tlearn: 0.2800230\ttotal: 2m 40s\tremaining: 3m 55s\n",
      "81:\tlearn: 0.2792365\ttotal: 2m 42s\tremaining: 3m 53s\n",
      "82:\tlearn: 0.2782876\ttotal: 2m 44s\tremaining: 3m 51s\n",
      "83:\tlearn: 0.2773971\ttotal: 2m 46s\tremaining: 3m 49s\n",
      "84:\tlearn: 0.2765984\ttotal: 2m 48s\tremaining: 3m 47s\n",
      "85:\tlearn: 0.2755516\ttotal: 2m 50s\tremaining: 3m 45s\n",
      "86:\tlearn: 0.2747021\ttotal: 2m 52s\tremaining: 3m 43s\n",
      "87:\tlearn: 0.2738845\ttotal: 2m 54s\tremaining: 3m 41s\n",
      "88:\tlearn: 0.2727859\ttotal: 2m 55s\tremaining: 3m 39s\n",
      "89:\tlearn: 0.2719643\ttotal: 2m 57s\tremaining: 3m 37s\n",
      "90:\tlearn: 0.2713024\ttotal: 2m 59s\tremaining: 3m 35s\n",
      "91:\tlearn: 0.2706658\ttotal: 3m 1s\tremaining: 3m 33s\n",
      "92:\tlearn: 0.2696728\ttotal: 3m 3s\tremaining: 3m 31s\n",
      "93:\tlearn: 0.2685348\ttotal: 3m 5s\tremaining: 3m 29s\n",
      "94:\tlearn: 0.2676027\ttotal: 3m 7s\tremaining: 3m 27s\n",
      "95:\tlearn: 0.2668245\ttotal: 3m 9s\tremaining: 3m 25s\n",
      "96:\tlearn: 0.2660745\ttotal: 3m 11s\tremaining: 3m 23s\n",
      "97:\tlearn: 0.2647026\ttotal: 3m 13s\tremaining: 3m 21s\n",
      "98:\tlearn: 0.2639037\ttotal: 3m 15s\tremaining: 3m 19s\n",
      "99:\tlearn: 0.2629679\ttotal: 3m 17s\tremaining: 3m 17s\n",
      "100:\tlearn: 0.2623895\ttotal: 3m 19s\tremaining: 3m 15s\n",
      "101:\tlearn: 0.2617094\ttotal: 3m 21s\tremaining: 3m 13s\n",
      "102:\tlearn: 0.2607330\ttotal: 3m 23s\tremaining: 3m 11s\n",
      "103:\tlearn: 0.2602065\ttotal: 3m 25s\tremaining: 3m 9s\n",
      "104:\tlearn: 0.2592027\ttotal: 3m 27s\tremaining: 3m 7s\n",
      "105:\tlearn: 0.2585440\ttotal: 3m 29s\tremaining: 3m 5s\n",
      "106:\tlearn: 0.2578689\ttotal: 3m 31s\tremaining: 3m 3s\n",
      "107:\tlearn: 0.2573050\ttotal: 3m 33s\tremaining: 3m 1s\n",
      "108:\tlearn: 0.2565157\ttotal: 3m 35s\tremaining: 2m 59s\n",
      "109:\tlearn: 0.2550803\ttotal: 3m 37s\tremaining: 2m 57s\n",
      "110:\tlearn: 0.2545233\ttotal: 3m 38s\tremaining: 2m 55s\n",
      "111:\tlearn: 0.2537876\ttotal: 3m 40s\tremaining: 2m 53s\n",
      "112:\tlearn: 0.2531574\ttotal: 3m 42s\tremaining: 2m 51s\n",
      "113:\tlearn: 0.2520838\ttotal: 3m 44s\tremaining: 2m 49s\n",
      "114:\tlearn: 0.2516091\ttotal: 3m 46s\tremaining: 2m 47s\n",
      "115:\tlearn: 0.2511030\ttotal: 3m 48s\tremaining: 2m 45s\n",
      "116:\tlearn: 0.2504936\ttotal: 3m 50s\tremaining: 2m 43s\n",
      "117:\tlearn: 0.2498276\ttotal: 3m 52s\tremaining: 2m 41s\n",
      "118:\tlearn: 0.2489878\ttotal: 3m 54s\tremaining: 2m 39s\n",
      "119:\tlearn: 0.2485320\ttotal: 3m 56s\tremaining: 2m 37s\n",
      "120:\tlearn: 0.2478015\ttotal: 3m 58s\tremaining: 2m 35s\n",
      "121:\tlearn: 0.2471875\ttotal: 3m 59s\tremaining: 2m 33s\n",
      "122:\tlearn: 0.2467883\ttotal: 4m 1s\tremaining: 2m 31s\n",
      "123:\tlearn: 0.2463726\ttotal: 4m 3s\tremaining: 2m 29s\n",
      "124:\tlearn: 0.2456825\ttotal: 4m 5s\tremaining: 2m 27s\n",
      "125:\tlearn: 0.2451551\ttotal: 4m 7s\tremaining: 2m 25s\n",
      "126:\tlearn: 0.2443641\ttotal: 4m 9s\tremaining: 2m 23s\n",
      "127:\tlearn: 0.2436821\ttotal: 4m 11s\tremaining: 2m 21s\n",
      "128:\tlearn: 0.2430951\ttotal: 4m 13s\tremaining: 2m 19s\n",
      "129:\tlearn: 0.2425735\ttotal: 4m 15s\tremaining: 2m 17s\n",
      "130:\tlearn: 0.2419493\ttotal: 4m 17s\tremaining: 2m 15s\n",
      "131:\tlearn: 0.2413894\ttotal: 4m 19s\tremaining: 2m 13s\n",
      "132:\tlearn: 0.2406368\ttotal: 4m 21s\tremaining: 2m 11s\n",
      "133:\tlearn: 0.2402692\ttotal: 4m 23s\tremaining: 2m 9s\n",
      "134:\tlearn: 0.2399459\ttotal: 4m 25s\tremaining: 2m 7s\n",
      "135:\tlearn: 0.2395468\ttotal: 4m 27s\tremaining: 2m 5s\n",
      "136:\tlearn: 0.2388032\ttotal: 4m 29s\tremaining: 2m 3s\n",
      "137:\tlearn: 0.2381676\ttotal: 4m 31s\tremaining: 2m 1s\n",
      "138:\tlearn: 0.2375559\ttotal: 4m 33s\tremaining: 2m\n",
      "139:\tlearn: 0.2369710\ttotal: 4m 35s\tremaining: 1m 58s\n",
      "140:\tlearn: 0.2363767\ttotal: 4m 37s\tremaining: 1m 56s\n",
      "141:\tlearn: 0.2357165\ttotal: 4m 39s\tremaining: 1m 54s\n",
      "142:\tlearn: 0.2351749\ttotal: 4m 41s\tremaining: 1m 52s\n",
      "143:\tlearn: 0.2343121\ttotal: 4m 43s\tremaining: 1m 50s\n",
      "144:\tlearn: 0.2336652\ttotal: 4m 45s\tremaining: 1m 48s\n",
      "145:\tlearn: 0.2332144\ttotal: 4m 47s\tremaining: 1m 46s\n",
      "146:\tlearn: 0.2328389\ttotal: 4m 49s\tremaining: 1m 44s\n",
      "147:\tlearn: 0.2325402\ttotal: 4m 50s\tremaining: 1m 42s\n",
      "148:\tlearn: 0.2319894\ttotal: 4m 52s\tremaining: 1m 40s\n",
      "149:\tlearn: 0.2313242\ttotal: 4m 54s\tremaining: 1m 38s\n",
      "150:\tlearn: 0.2309507\ttotal: 4m 56s\tremaining: 1m 36s\n",
      "151:\tlearn: 0.2301606\ttotal: 4m 58s\tremaining: 1m 34s\n",
      "152:\tlearn: 0.2298742\ttotal: 5m\tremaining: 1m 32s\n",
      "153:\tlearn: 0.2293255\ttotal: 5m 2s\tremaining: 1m 30s\n",
      "154:\tlearn: 0.2289878\ttotal: 5m 4s\tremaining: 1m 28s\n",
      "155:\tlearn: 0.2283866\ttotal: 5m 6s\tremaining: 1m 26s\n",
      "156:\tlearn: 0.2280116\ttotal: 5m 8s\tremaining: 1m 24s\n",
      "157:\tlearn: 0.2272270\ttotal: 5m 10s\tremaining: 1m 22s\n",
      "158:\tlearn: 0.2267454\ttotal: 5m 12s\tremaining: 1m 20s\n",
      "159:\tlearn: 0.2264580\ttotal: 5m 14s\tremaining: 1m 18s\n",
      "160:\tlearn: 0.2257204\ttotal: 5m 16s\tremaining: 1m 16s\n",
      "161:\tlearn: 0.2250611\ttotal: 5m 18s\tremaining: 1m 14s\n",
      "162:\tlearn: 0.2244282\ttotal: 5m 20s\tremaining: 1m 12s\n",
      "163:\tlearn: 0.2238602\ttotal: 5m 22s\tremaining: 1m 10s\n",
      "164:\tlearn: 0.2231781\ttotal: 5m 24s\tremaining: 1m 8s\n",
      "165:\tlearn: 0.2223604\ttotal: 5m 26s\tremaining: 1m 6s\n",
      "166:\tlearn: 0.2218607\ttotal: 5m 28s\tremaining: 1m 4s\n",
      "167:\tlearn: 0.2215432\ttotal: 5m 30s\tremaining: 1m 2s\n",
      "168:\tlearn: 0.2211839\ttotal: 5m 32s\tremaining: 1m\n",
      "169:\tlearn: 0.2209208\ttotal: 5m 34s\tremaining: 59s\n",
      "170:\tlearn: 0.2206745\ttotal: 5m 36s\tremaining: 57s\n",
      "171:\tlearn: 0.2202467\ttotal: 5m 37s\tremaining: 55s\n",
      "172:\tlearn: 0.2196004\ttotal: 5m 39s\tremaining: 53.1s\n",
      "173:\tlearn: 0.2192574\ttotal: 5m 41s\tremaining: 51.1s\n",
      "174:\tlearn: 0.2189677\ttotal: 5m 43s\tremaining: 49.1s\n",
      "175:\tlearn: 0.2182295\ttotal: 5m 45s\tremaining: 47.1s\n",
      "176:\tlearn: 0.2177295\ttotal: 5m 47s\tremaining: 45.2s\n",
      "177:\tlearn: 0.2172201\ttotal: 5m 49s\tremaining: 43.2s\n",
      "178:\tlearn: 0.2168882\ttotal: 5m 51s\tremaining: 41.2s\n",
      "179:\tlearn: 0.2164426\ttotal: 5m 53s\tremaining: 39.3s\n",
      "180:\tlearn: 0.2161949\ttotal: 5m 55s\tremaining: 37.3s\n",
      "181:\tlearn: 0.2156723\ttotal: 5m 57s\tremaining: 35.3s\n",
      "182:\tlearn: 0.2154297\ttotal: 5m 59s\tremaining: 33.4s\n",
      "183:\tlearn: 0.2150572\ttotal: 6m 1s\tremaining: 31.4s\n",
      "184:\tlearn: 0.2147261\ttotal: 6m 2s\tremaining: 29.4s\n",
      "185:\tlearn: 0.2143104\ttotal: 6m 4s\tremaining: 27.5s\n",
      "186:\tlearn: 0.2138792\ttotal: 6m 7s\tremaining: 25.5s\n",
      "187:\tlearn: 0.2136223\ttotal: 6m 8s\tremaining: 23.6s\n",
      "188:\tlearn: 0.2130604\ttotal: 6m 11s\tremaining: 21.6s\n",
      "189:\tlearn: 0.2126859\ttotal: 6m 13s\tremaining: 19.6s\n",
      "190:\tlearn: 0.2124503\ttotal: 6m 15s\tremaining: 17.7s\n",
      "191:\tlearn: 0.2120206\ttotal: 6m 17s\tremaining: 15.7s\n",
      "192:\tlearn: 0.2114518\ttotal: 6m 19s\tremaining: 13.7s\n",
      "193:\tlearn: 0.2107571\ttotal: 6m 21s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2102683\ttotal: 6m 23s\tremaining: 9.82s\n",
      "195:\tlearn: 0.2097178\ttotal: 6m 24s\tremaining: 7.86s\n",
      "196:\tlearn: 0.2094551\ttotal: 6m 26s\tremaining: 5.89s\n",
      "197:\tlearn: 0.2088002\ttotal: 6m 28s\tremaining: 3.93s\n",
      "198:\tlearn: 0.2085729\ttotal: 6m 30s\tremaining: 1.96s\n",
      "199:\tlearn: 0.2081758\ttotal: 6m 32s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "f1_crossval_CBC = cross_val_score(model,\n",
    "                                  features_train,\n",
    "                                  target_train, \n",
    "                                  scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7358951388405315"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_crossval_CBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_valid_CBC = f1_score(target_valid, predictions_valid_CBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395861327600106"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_valid_CBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики CatBoostRegressor чуть ниже логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 при валидационной выборке</th>\n",
       "      <th>Целевая метрика достигнута</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.760836</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.642331</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.739586</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 при валидационной выборке  \\\n",
       "LogisticRegression                          0.760836   \n",
       "DecisionTreeClassifier                      0.642331   \n",
       "CatBoostClassifier                          0.739586   \n",
       "\n",
       "                        Целевая метрика достигнута  \n",
       "LogisticRegression                            True  \n",
       "DecisionTreeClassifier                       False  \n",
       "CatBoostClassifier                           False  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier']\n",
    "data = {'F1 при валидационной выборке':[f1_valid_LR,\n",
    "                                        f1_valid_DTC,\n",
    "                                        f1_valid_CBC]}\n",
    "\n",
    "\n",
    "comp_data = pd.DataFrame(data=data, index=index)\n",
    "comp_data['Целевая метрика достигнута'] = comp_data['F1 при валидационной выборке'] > 0.75\n",
    "comp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из трех обученных моделей на кросс-валидационной выборке целевой метрики качества удалось достигнуть только LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу этой модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка лучшей модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_LR = model_LR.predict(features_test)\n",
    "f1_test_LR = f1_score(target_test, predictions_test_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7550728779651329"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая метрика достигнута и на работе с тестовой выборкой — а значит, модель пригодна к использованию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы нами были загружены и изучены текстовые данные с комментариями англоязычных пользователей.\n",
    "\n",
    "При изучении целевого признака было замечено, что в датасете имеется дисбаланс классов — по этой причине в дальнейшей работе у всех моделей использовался параметр `class_weight`.\n",
    "\n",
    "Перед обучением модели тексты были лемматизированы т.е. приведены к начальной форме. Затем мы применили объект TfidfVectorizer для подсчета TF-IDF по корпусу текстов (комментариев) и таким образом создали векторизированные признаки.\n",
    "\n",
    "После создания признаков, весь датасет был разделен на 3 выборки в соотношении 3:1:1 — обучающую, валидационную и тестовую.\n",
    "\n",
    "Затем мы обучили на тестовой выборке три модели — LogisticRegression, DecisionTreeClassifier, CatBoostClassifier. Их работа была проверена на валидационной выборке — лучший результат показала модель LogisticRegression. Она же стала единственной моделью, которая смогла добиться целевой метрики заказчика F1 — более 0.75.\n",
    "\n",
    "С целью оценить адекватность работы лучшей модели и возможность ее дальнейшего использования на незнакомых текстах, мы оценили ее работу на тестовой выборке.\n",
    "\n",
    "Логистическая регрессия пригодна для работы с незнакомыми текстами, и более того, быстро обучается и предсказывает. Для повышенной точности можно применить более долго обучающиеся модели или подготовить текст и признаки с помощью внешних библиотек (например, BERT)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1733,
    "start_time": "2022-08-26T20:44:38.552Z"
   },
   {
    "duration": 167,
    "start_time": "2022-08-26T20:45:01.458Z"
   },
   {
    "duration": 2349,
    "start_time": "2022-08-26T20:45:13.450Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-26T20:45:22.166Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-26T20:45:46.036Z"
   },
   {
    "duration": 32,
    "start_time": "2022-08-26T20:45:53.370Z"
   },
   {
    "duration": 55,
    "start_time": "2022-08-26T20:46:04.552Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-26T20:46:40.164Z"
   },
   {
    "duration": 111,
    "start_time": "2022-08-26T20:46:54.913Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-26T20:47:05.574Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-26T20:47:30.970Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-26T20:48:41.499Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-26T20:49:04.108Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-26T20:49:53.284Z"
   },
   {
    "duration": 96021,
    "start_time": "2022-08-26T20:49:57.535Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-26T20:52:02.512Z"
   },
   {
    "duration": 1441,
    "start_time": "2022-08-26T20:52:26.911Z"
   },
   {
    "duration": 738,
    "start_time": "2022-08-26T20:52:28.354Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-26T20:52:29.165Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-26T20:52:29.187Z"
   },
   {
    "duration": 33,
    "start_time": "2022-08-26T20:52:29.198Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-26T20:52:29.232Z"
   },
   {
    "duration": 120,
    "start_time": "2022-08-26T20:52:29.239Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-26T20:52:29.360Z"
   },
   {
    "duration": 21,
    "start_time": "2022-08-26T20:52:29.368Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-26T20:52:29.391Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-26T20:52:29.395Z"
   },
   {
    "duration": 94366,
    "start_time": "2022-08-26T20:52:29.402Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-26T20:54:03.769Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-26T20:54:03.786Z"
   },
   {
    "duration": 34,
    "start_time": "2022-08-26T20:57:10.724Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-26T20:57:15.866Z"
   },
   {
    "duration": 148,
    "start_time": "2022-08-26T21:07:02.999Z"
   },
   {
    "duration": 46,
    "start_time": "2022-08-26T21:07:18.206Z"
   },
   {
    "duration": 1708,
    "start_time": "2022-08-28T04:54:47.781Z"
   },
   {
    "duration": 2383,
    "start_time": "2022-08-28T04:54:49.491Z"
   },
   {
    "duration": 84,
    "start_time": "2022-08-28T04:54:51.876Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-28T04:54:51.962Z"
   },
   {
    "duration": 48,
    "start_time": "2022-08-28T04:54:51.979Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T04:54:52.029Z"
   },
   {
    "duration": 116,
    "start_time": "2022-08-28T04:54:52.036Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T04:54:52.154Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T04:54:52.163Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T04:54:52.179Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-28T04:54:52.183Z"
   },
   {
    "duration": 90433,
    "start_time": "2022-08-28T04:54:52.211Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T04:56:22.646Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T04:56:22.657Z"
   },
   {
    "duration": 51,
    "start_time": "2022-08-28T04:56:22.670Z"
   },
   {
    "duration": 53,
    "start_time": "2022-08-28T04:56:22.723Z"
   },
   {
    "duration": 429,
    "start_time": "2022-08-28T05:00:24.907Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T05:01:20.895Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-28T05:01:47.188Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T05:02:03.236Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T05:02:32.053Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T05:03:10.827Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T05:04:06.841Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T05:04:51.325Z"
   },
   {
    "duration": 11308,
    "start_time": "2022-08-28T05:06:09.545Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T05:07:15.385Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T05:07:24.663Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T05:07:42.193Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T05:13:37.863Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T05:21:46.357Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T05:21:59.862Z"
   },
   {
    "duration": 8980,
    "start_time": "2022-08-28T05:24:54.578Z"
   },
   {
    "duration": 517455,
    "start_time": "2022-08-28T05:25:12.270Z"
   },
   {
    "duration": 498692,
    "start_time": "2022-08-28T05:34:15.827Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T05:49:13.111Z"
   },
   {
    "duration": 44064,
    "start_time": "2022-08-28T05:52:11.661Z"
   },
   {
    "duration": 47672,
    "start_time": "2022-08-28T05:53:25.743Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T05:54:35.557Z"
   },
   {
    "duration": 1634,
    "start_time": "2022-08-28T07:32:33.899Z"
   },
   {
    "duration": 896,
    "start_time": "2022-08-28T07:32:35.535Z"
   },
   {
    "duration": 97,
    "start_time": "2022-08-28T07:32:36.433Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T07:32:36.532Z"
   },
   {
    "duration": 38,
    "start_time": "2022-08-28T07:32:36.544Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T07:32:36.584Z"
   },
   {
    "duration": 121,
    "start_time": "2022-08-28T07:32:36.591Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T07:32:36.714Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-28T07:32:36.722Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T07:32:36.738Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T07:32:36.742Z"
   },
   {
    "duration": 94069,
    "start_time": "2022-08-28T07:32:36.752Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T07:34:10.823Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-28T07:34:10.829Z"
   },
   {
    "duration": 41,
    "start_time": "2022-08-28T07:34:10.849Z"
   },
   {
    "duration": 50,
    "start_time": "2022-08-28T07:34:10.891Z"
   },
   {
    "duration": 197,
    "start_time": "2022-08-28T07:34:10.943Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T07:34:11.142Z"
   },
   {
    "duration": 11154,
    "start_time": "2022-08-28T07:34:11.147Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T07:34:22.303Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T07:34:22.312Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T07:34:22.327Z"
   },
   {
    "duration": 493276,
    "start_time": "2022-08-28T07:34:22.335Z"
   },
   {
    "duration": 90,
    "start_time": "2022-08-28T07:42:35.621Z"
   },
   {
    "duration": 42806,
    "start_time": "2022-08-28T07:42:35.713Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T07:43:18.521Z"
   },
   {
    "duration": 1662,
    "start_time": "2022-08-28T08:18:39.202Z"
   },
   {
    "duration": 1004,
    "start_time": "2022-08-28T08:18:40.866Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T08:18:41.872Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-28T08:18:41.884Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-28T08:18:41.915Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T08:18:41.963Z"
   },
   {
    "duration": 108,
    "start_time": "2022-08-28T08:18:41.971Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T08:18:42.080Z"
   },
   {
    "duration": 31,
    "start_time": "2022-08-28T08:18:42.089Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T08:18:42.125Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T08:18:42.130Z"
   },
   {
    "duration": 97834,
    "start_time": "2022-08-28T08:18:42.141Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T08:20:19.977Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T08:20:19.985Z"
   },
   {
    "duration": 67,
    "start_time": "2022-08-28T08:20:19.994Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-28T08:20:20.063Z"
   },
   {
    "duration": 210,
    "start_time": "2022-08-28T08:20:20.107Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T08:20:20.321Z"
   },
   {
    "duration": 11863,
    "start_time": "2022-08-28T08:20:20.326Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T08:20:32.191Z"
   },
   {
    "duration": 33,
    "start_time": "2022-08-28T08:20:32.195Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-28T08:20:32.230Z"
   },
   {
    "duration": 516289,
    "start_time": "2022-08-28T08:20:32.244Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T08:29:08.613Z"
   },
   {
    "duration": 45102,
    "start_time": "2022-08-28T08:29:08.628Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T08:29:53.811Z"
   },
   {
    "duration": 306,
    "start_time": "2022-08-28T08:46:37.609Z"
   },
   {
    "duration": 10206,
    "start_time": "2022-08-28T08:46:38.019Z"
   },
   {
    "duration": 4487,
    "start_time": "2022-08-28T08:46:48.230Z"
   },
   {
    "duration": 1301,
    "start_time": "2022-08-28T08:46:52.727Z"
   },
   {
    "duration": 299,
    "start_time": "2022-08-28T08:46:54.111Z"
   },
   {
    "duration": 604,
    "start_time": "2022-08-28T08:46:54.412Z"
   },
   {
    "duration": 196,
    "start_time": "2022-08-28T08:46:55.026Z"
   },
   {
    "duration": 1107,
    "start_time": "2022-08-28T08:46:55.308Z"
   },
   {
    "duration": 199,
    "start_time": "2022-08-28T08:46:56.420Z"
   },
   {
    "duration": 286,
    "start_time": "2022-08-28T08:46:56.630Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-28T08:46:57.014Z"
   },
   {
    "duration": 381,
    "start_time": "2022-08-28T08:46:57.031Z"
   },
   {
    "duration": 416014,
    "start_time": "2022-08-28T08:46:57.413Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T08:53:53.429Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T08:53:53.438Z"
   },
   {
    "duration": 111,
    "start_time": "2022-08-28T08:53:53.509Z"
   },
   {
    "duration": 101,
    "start_time": "2022-08-28T08:53:53.623Z"
   },
   {
    "duration": 129,
    "start_time": "2022-08-28T08:53:53.727Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T08:53:53.859Z"
   },
   {
    "duration": 26363,
    "start_time": "2022-08-28T08:53:53.864Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T08:54:20.229Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-28T08:54:20.234Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T08:54:20.313Z"
   },
   {
    "duration": 698398,
    "start_time": "2022-08-28T08:54:20.324Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T09:05:58.723Z"
   },
   {
    "duration": 55199,
    "start_time": "2022-08-28T09:05:58.730Z"
   },
   {
    "duration": 80,
    "start_time": "2022-08-28T09:06:53.931Z"
   },
   {
    "duration": 278903,
    "start_time": "2022-08-28T09:06:54.021Z"
   },
   {
    "duration": 1,
    "start_time": "2022-08-28T09:11:32.926Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T09:11:32.928Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T09:11:32.929Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T09:11:32.931Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T09:11:32.932Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T09:11:32.933Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T09:11:39.076Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-28T09:11:39.643Z"
   },
   {
    "duration": 1779,
    "start_time": "2022-08-28T09:11:40.314Z"
   },
   {
    "duration": 711469,
    "start_time": "2022-08-28T09:12:08.362Z"
   },
   {
    "duration": 80,
    "start_time": "2022-08-28T09:25:33.462Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-28T09:25:45.903Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-28T09:26:04.243Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-28T09:26:58.582Z"
   },
   {
    "duration": 57,
    "start_time": "2022-08-28T09:27:18.359Z"
   },
   {
    "duration": 60987,
    "start_time": "2022-08-28T09:27:23.610Z"
   },
   {
    "duration": 2979,
    "start_time": "2022-08-28T09:29:47.549Z"
   },
   {
    "duration": 1894,
    "start_time": "2022-08-28T09:29:50.530Z"
   },
   {
    "duration": 201,
    "start_time": "2022-08-28T09:29:52.427Z"
   },
   {
    "duration": 79,
    "start_time": "2022-08-28T09:29:52.631Z"
   },
   {
    "duration": 103,
    "start_time": "2022-08-28T09:29:52.713Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T09:29:52.823Z"
   },
   {
    "duration": 280,
    "start_time": "2022-08-28T09:29:52.832Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T09:29:53.114Z"
   },
   {
    "duration": 82,
    "start_time": "2022-08-28T09:29:53.128Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T09:29:53.219Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-28T09:29:53.225Z"
   },
   {
    "duration": 221502,
    "start_time": "2022-08-28T09:29:53.246Z"
   },
   {
    "duration": 63,
    "start_time": "2022-08-28T09:33:34.750Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T09:33:34.818Z"
   },
   {
    "duration": 116,
    "start_time": "2022-08-28T09:33:34.829Z"
   },
   {
    "duration": 106,
    "start_time": "2022-08-28T09:33:34.946Z"
   },
   {
    "duration": 217,
    "start_time": "2022-08-28T09:33:35.055Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T09:33:35.274Z"
   },
   {
    "duration": 26616,
    "start_time": "2022-08-28T09:33:35.310Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T09:34:01.928Z"
   },
   {
    "duration": 77,
    "start_time": "2022-08-28T09:34:01.935Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-28T09:34:02.014Z"
   },
   {
    "duration": 686382,
    "start_time": "2022-08-28T09:34:02.027Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T09:45:28.412Z"
   },
   {
    "duration": 54091,
    "start_time": "2022-08-28T09:45:28.420Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T09:46:22.513Z"
   },
   {
    "duration": 37,
    "start_time": "2022-08-28T09:46:22.520Z"
   },
   {
    "duration": 21,
    "start_time": "2022-08-28T09:46:22.613Z"
   },
   {
    "duration": 32,
    "start_time": "2022-08-28T19:11:01.336Z"
   },
   {
    "duration": 5210229,
    "start_time": "2022-08-28T19:11:06.230Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T20:45:54.456Z"
   },
   {
    "duration": 51,
    "start_time": "2022-08-28T20:46:06.299Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T20:46:12.771Z"
   },
   {
    "duration": 57,
    "start_time": "2022-08-28T20:46:18.971Z"
   },
   {
    "duration": 1407320,
    "start_time": "2022-08-28T20:46:25.547Z"
   },
   {
    "duration": 59,
    "start_time": "2022-08-28T21:09:52.869Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T21:13:08.356Z"
   },
   {
    "duration": 32264,
    "start_time": "2022-08-28T21:15:06.184Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T21:15:50.805Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T21:16:55.621Z"
   },
   {
    "duration": 412624,
    "start_time": "2022-08-28T21:16:56.873Z"
   },
   {
    "duration": 385,
    "start_time": "2022-08-28T21:24:36.500Z"
   },
   {
    "duration": 1733141,
    "start_time": "2022-08-28T21:24:49.048Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T04:34:36.014Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T04:34:40.077Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T04:34:47.091Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-29T04:42:55.574Z"
   },
   {
    "duration": 988,
    "start_time": "2022-08-29T04:43:04.523Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T04:43:20.422Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-29T04:50:42.781Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T04:50:52.270Z"
   },
   {
    "duration": 1679,
    "start_time": "2022-08-29T20:36:51.129Z"
   },
   {
    "duration": 2263,
    "start_time": "2022-08-29T20:36:57.978Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T20:37:01.007Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T20:37:04.759Z"
   },
   {
    "duration": 103,
    "start_time": "2022-08-29T20:37:05.274Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T20:37:09.924Z"
   },
   {
    "duration": 109,
    "start_time": "2022-08-29T20:37:10.433Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-29T20:37:13.337Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T20:37:35.271Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T20:37:58.828Z"
   },
   {
    "duration": 55,
    "start_time": "2022-08-29T20:38:49.197Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T20:39:40.919Z"
   },
   {
    "duration": 46,
    "start_time": "2022-08-29T20:51:29.500Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T20:51:50.899Z"
   },
   {
    "duration": 187,
    "start_time": "2022-08-29T20:52:11.865Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T20:52:23.977Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T20:52:24.206Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-29T20:52:25.842Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T20:54:01.535Z"
   },
   {
    "duration": 1283,
    "start_time": "2022-08-29T20:54:04.868Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T20:54:51.480Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T20:55:38.589Z"
   },
   {
    "duration": 463,
    "start_time": "2022-08-29T20:58:07.471Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T20:58:19.644Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T20:58:20.523Z"
   },
   {
    "duration": 93,
    "start_time": "2022-08-29T20:58:21.926Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T20:58:52.828Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T20:58:53.181Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T20:59:17.252Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T20:59:17.762Z"
   },
   {
    "duration": 1281011,
    "start_time": "2022-08-29T20:59:47.087Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:21:08.100Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T21:21:50.772Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T21:21:52.259Z"
   },
   {
    "duration": 38,
    "start_time": "2022-08-29T21:25:09.533Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-29T21:25:14.851Z"
   },
   {
    "duration": 158,
    "start_time": "2022-08-29T21:25:18.611Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T21:25:19.259Z"
   },
   {
    "duration": 6049,
    "start_time": "2022-08-29T21:25:32.058Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:26:47.137Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T21:26:56.524Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T21:26:56.929Z"
   },
   {
    "duration": 485654,
    "start_time": "2022-08-29T21:27:09.145Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T21:35:14.888Z"
   },
   {
    "duration": 42878,
    "start_time": "2022-08-29T21:35:33.917Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:36:39.644Z"
   },
   {
    "duration": 1276125,
    "start_time": "2022-08-29T21:36:46.217Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:58:02.344Z"
   },
   {
    "duration": 30106,
    "start_time": "2022-08-29T21:58:02.350Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:58:32.458Z"
   },
   {
    "duration": 27976,
    "start_time": "2022-08-29T21:59:21.350Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T21:59:52.698Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T21:59:58.232Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T21:59:59.017Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-29T21:59:59.533Z"
   },
   {
    "duration": 357216,
    "start_time": "2022-08-29T22:00:00.550Z"
   },
   {
    "duration": 350,
    "start_time": "2022-08-29T22:08:06.373Z"
   },
   {
    "duration": 2054875,
    "start_time": "2022-08-29T22:08:14.134Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T22:42:34.067Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T22:42:35.365Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T22:42:35.880Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T22:42:42.933Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-29T22:42:49.419Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T22:42:49.772Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.372px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
